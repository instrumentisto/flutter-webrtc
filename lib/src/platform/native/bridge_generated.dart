// AUTO GENERATED FILE, DO NOT EDIT.
// Generated by `flutter_rust_bridge`.

// ignore_for_file: non_constant_identifier_names, unused_element, duplicate_ignore, directives_ordering, curly_braces_in_flow_control_structures, unnecessary_lambdas, slash_for_doc_comments, prefer_const_literals_to_create_immutables, implicit_dynamic_list_literal, duplicate_import, unused_import, prefer_single_quotes

import 'dart:convert';
import 'dart:typed_data';

import 'dart:convert';
import 'dart:typed_data';
import 'package:flutter_rust_bridge/flutter_rust_bridge.dart';
import 'dart:ffi' as ffi;

abstract class FlutterWebrtcNative {
  Future<void> webrtcInit({dynamic hint});

  Future<void> createVideoSink(
      {required int sinkId,
      required int trackId,
      required int callbackPtr,
      dynamic hint});

  Future<void> disposeVideoSink({required int sinkId, dynamic hint});

  Future<List<MediaDeviceInfo>> enumerateDevices({dynamic hint});

  Future<List<MediaStreamTrack_>> getMedia(
      {required MediaStreamConstraints constraints,
      required bool isDisplay,
      dynamic hint});
}

/// Specifies the nature and settings of the audio [`MediaStreamTrack`]
/// returned by [`Webrtc::get_users_media()`].
class AudioConstraints {
  /// Indicates whether [`Webrtc::get_users_media()`] should obtain video
  /// track. All other args will be ignored if `required` is set to
  /// `false`.
  final bool required;

  /// The identifier of the device generating the content of the
  /// [`MediaStreamTrack`]. First device will be chosen if empty
  /// [`String`] is provided.
  ///
  /// __NOTE__: There can be only one active recording device at a time,
  /// so changing device will affect all previously obtained audio tracks.
  final String deviceId;

  AudioConstraints({
    required this.required,
    required this.deviceId,
  });
}

/// Information describing a single media input or output device.
class MediaDeviceInfo {
  /// Unique identifier for the represented device.
  final String deviceId;

  /// Kind of the represented device.
  final MediaDeviceKind kind;

  /// Label describing the represented device.
  final String label;

  MediaDeviceInfo({
    required this.deviceId,
    required this.kind,
    required this.label,
  });
}

/// Possible kinds of media devices.
enum MediaDeviceKind {
  AudioInput,
  AudioOutput,
  VideoInput,
}

/// The [MediaStreamConstraints] is used to instruct what sort of
/// [`MediaStreamTrack`]s to include in the [`MediaStream`] returned by
/// [`Webrtc::get_users_media()`].
class MediaStreamConstraints {
  /// Specifies the nature and settings of the video [`MediaStreamTrack`].
  final AudioConstraints? audio;

  /// Specifies the nature and settings of the audio [`MediaStreamTrack`].
  final VideoConstraints? video;

  MediaStreamConstraints({
    this.audio,
    this.video,
  });
}

/// Representation of a single media track within a [`MediaStream`].
///
/// Typically, these are audio or video tracks, but other track types may
/// exist as well.
class MediaStreamTrack_ {
  /// Unique identifier (GUID) for the track
  final int id;

  /// Label that identifies the track source, as in "internal microphone".
  final String label;

  /// [`MediaType`] of the current [`MediaStreamTrack`].
  final MediaType kind;

  /// The `enabled` property on the [`MediaStreamTrack`] interface is a
  /// `enabled` value which is `true` if the track is allowed to render
  /// the source stream or `false` if it is not. This can be used to
  /// intentionally mute a track.
  final bool enabled;

  MediaStreamTrack_({
    required this.id,
    required this.label,
    required this.kind,
    required this.enabled,
  });
}

enum MediaType {
  Audio,
  Video,
}

/// Specifies the nature and settings of the video [`MediaStreamTrack`]
/// returned by [`Webrtc::get_users_media()`].
class VideoConstraints {
  /// The identifier of the device generating the content of the
  /// [`MediaStreamTrack`]. First device will be chosen if empty
  /// [`String`] is provided.
  final String deviceId;

  /// The width, in pixels.
  final int width;

  /// The height, in pixels.
  final int height;

  /// The exact frame rate (frames per second).
  final int frameRate;

  VideoConstraints({
    required this.deviceId,
    required this.width,
    required this.height,
    required this.frameRate,
  });
}

class FlutterWebrtcNativeImpl
    extends FlutterRustBridgeBase<FlutterWebrtcNativeWire>
    implements FlutterWebrtcNative {
  factory FlutterWebrtcNativeImpl(ffi.DynamicLibrary dylib) =>
      FlutterWebrtcNativeImpl.raw(FlutterWebrtcNativeWire(dylib));

  FlutterWebrtcNativeImpl.raw(FlutterWebrtcNativeWire inner) : super(inner);

  Future<void> webrtcInit({dynamic hint}) =>
      executeNormal(FlutterRustBridgeTask(
        callFfi: (port_) => inner.wire_webrtc_init(port_),
        parseSuccessData: _wire2api_unit,
        constMeta: const FlutterRustBridgeTaskConstMeta(
          debugName: "webrtc_init",
          argNames: [],
        ),
        argValues: [],
        hint: hint,
      ));

  Future<void> createVideoSink(
          {required int sinkId,
          required int trackId,
          required int callbackPtr,
          dynamic hint}) =>
      executeNormal(FlutterRustBridgeTask(
        callFfi: (port_) => inner.wire_create_video_sink(
            port_,
            _api2wire_i64(sinkId),
            _api2wire_u64(trackId),
            _api2wire_u64(callbackPtr)),
        parseSuccessData: _wire2api_unit,
        constMeta: const FlutterRustBridgeTaskConstMeta(
          debugName: "create_video_sink",
          argNames: ["sinkId", "trackId", "callbackPtr"],
        ),
        argValues: [sinkId, trackId, callbackPtr],
        hint: hint,
      ));

  Future<void> disposeVideoSink({required int sinkId, dynamic hint}) =>
      executeNormal(FlutterRustBridgeTask(
        callFfi: (port_) =>
            inner.wire_dispose_video_sink(port_, _api2wire_i64(sinkId)),
        parseSuccessData: _wire2api_unit,
        constMeta: const FlutterRustBridgeTaskConstMeta(
          debugName: "dispose_video_sink",
          argNames: ["sinkId"],
        ),
        argValues: [sinkId],
        hint: hint,
      ));

  Future<List<MediaDeviceInfo>> enumerateDevices({dynamic hint}) =>
      executeNormal(FlutterRustBridgeTask(
        callFfi: (port_) => inner.wire_enumerate_devices(port_),
        parseSuccessData: _wire2api_list_media_device_info,
        constMeta: const FlutterRustBridgeTaskConstMeta(
          debugName: "enumerate_devices",
          argNames: [],
        ),
        argValues: [],
        hint: hint,
      ));

  Future<List<MediaStreamTrack_>> getMedia(
          {required MediaStreamConstraints constraints,
          required bool isDisplay,
          dynamic hint}) =>
      executeNormal(FlutterRustBridgeTask(
        callFfi: (port_) => inner.wire_get_media(
            port_,
            _api2wire_box_autoadd_media_stream_constraints(constraints),
            isDisplay),
        parseSuccessData: _wire2api_list_media_stream_track,
        constMeta: const FlutterRustBridgeTaskConstMeta(
          debugName: "get_media",
          argNames: ["constraints", "isDisplay"],
        ),
        argValues: [constraints, isDisplay],
        hint: hint,
      ));

  // Section: api2wire
  ffi.Pointer<wire_uint_8_list> _api2wire_String(String raw) {
    return _api2wire_uint_8_list(utf8.encoder.convert(raw));
  }

  int _api2wire_bool(bool raw) {
    return raw ? 1 : 0;
  }

  ffi.Pointer<wire_AudioConstraints> _api2wire_box_autoadd_audio_constraints(
      AudioConstraints raw) {
    final ptr = inner.new_box_autoadd_audio_constraints();
    _api_fill_to_wire_audio_constraints(raw, ptr.ref);
    return ptr;
  }

  ffi.Pointer<wire_MediaStreamConstraints>
      _api2wire_box_autoadd_media_stream_constraints(
          MediaStreamConstraints raw) {
    final ptr = inner.new_box_autoadd_media_stream_constraints();
    _api_fill_to_wire_media_stream_constraints(raw, ptr.ref);
    return ptr;
  }

  ffi.Pointer<wire_VideoConstraints> _api2wire_box_autoadd_video_constraints(
      VideoConstraints raw) {
    final ptr = inner.new_box_autoadd_video_constraints();
    _api_fill_to_wire_video_constraints(raw, ptr.ref);
    return ptr;
  }

  int _api2wire_i64(int raw) {
    return raw;
  }

  ffi.Pointer<wire_AudioConstraints>
      _api2wire_opt_box_autoadd_audio_constraints(AudioConstraints? raw) {
    return raw == null
        ? ffi.nullptr
        : _api2wire_box_autoadd_audio_constraints(raw);
  }

  ffi.Pointer<wire_VideoConstraints>
      _api2wire_opt_box_autoadd_video_constraints(VideoConstraints? raw) {
    return raw == null
        ? ffi.nullptr
        : _api2wire_box_autoadd_video_constraints(raw);
  }

  int _api2wire_u32(int raw) {
    return raw;
  }

  int _api2wire_u64(int raw) {
    return raw;
  }

  int _api2wire_u8(int raw) {
    return raw;
  }

  ffi.Pointer<wire_uint_8_list> _api2wire_uint_8_list(Uint8List raw) {
    final ans = inner.new_uint_8_list(raw.length);
    ans.ref.ptr.asTypedList(raw.length).setAll(0, raw);
    return ans;
  }

  // Section: api_fill_to_wire

  void _api_fill_to_wire_audio_constraints(
      AudioConstraints apiObj, wire_AudioConstraints wireObj) {
    wireObj.required = _api2wire_bool(apiObj.required);
    wireObj.device_id = _api2wire_String(apiObj.deviceId);
  }

  void _api_fill_to_wire_box_autoadd_audio_constraints(
      AudioConstraints apiObj, ffi.Pointer<wire_AudioConstraints> wireObj) {
    _api_fill_to_wire_audio_constraints(apiObj, wireObj.ref);
  }

  void _api_fill_to_wire_box_autoadd_media_stream_constraints(
      MediaStreamConstraints apiObj,
      ffi.Pointer<wire_MediaStreamConstraints> wireObj) {
    _api_fill_to_wire_media_stream_constraints(apiObj, wireObj.ref);
  }

  void _api_fill_to_wire_box_autoadd_video_constraints(
      VideoConstraints apiObj, ffi.Pointer<wire_VideoConstraints> wireObj) {
    _api_fill_to_wire_video_constraints(apiObj, wireObj.ref);
  }

  void _api_fill_to_wire_media_stream_constraints(
      MediaStreamConstraints apiObj, wire_MediaStreamConstraints wireObj) {
    wireObj.audio = _api2wire_opt_box_autoadd_audio_constraints(apiObj.audio);
    wireObj.video = _api2wire_opt_box_autoadd_video_constraints(apiObj.video);
  }

  void _api_fill_to_wire_opt_box_autoadd_audio_constraints(
      AudioConstraints? apiObj, ffi.Pointer<wire_AudioConstraints> wireObj) {
    if (apiObj != null)
      _api_fill_to_wire_box_autoadd_audio_constraints(apiObj, wireObj);
  }

  void _api_fill_to_wire_opt_box_autoadd_video_constraints(
      VideoConstraints? apiObj, ffi.Pointer<wire_VideoConstraints> wireObj) {
    if (apiObj != null)
      _api_fill_to_wire_box_autoadd_video_constraints(apiObj, wireObj);
  }

  void _api_fill_to_wire_video_constraints(
      VideoConstraints apiObj, wire_VideoConstraints wireObj) {
    wireObj.device_id = _api2wire_String(apiObj.deviceId);
    wireObj.width = _api2wire_u32(apiObj.width);
    wireObj.height = _api2wire_u32(apiObj.height);
    wireObj.frame_rate = _api2wire_u32(apiObj.frameRate);
  }
}

// Section: wire2api
String _wire2api_String(dynamic raw) {
  return raw as String;
}

bool _wire2api_bool(dynamic raw) {
  return raw as bool;
}

List<MediaDeviceInfo> _wire2api_list_media_device_info(dynamic raw) {
  return (raw as List<dynamic>).map(_wire2api_media_device_info).toList();
}

List<MediaStreamTrack_> _wire2api_list_media_stream_track(dynamic raw) {
  return (raw as List<dynamic>).map(_wire2api_media_stream_track).toList();
}

MediaDeviceInfo _wire2api_media_device_info(dynamic raw) {
  final arr = raw as List<dynamic>;
  if (arr.length != 3)
    throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
  return MediaDeviceInfo(
    deviceId: _wire2api_String(arr[0]),
    kind: _wire2api_media_device_kind(arr[1]),
    label: _wire2api_String(arr[2]),
  );
}

MediaDeviceKind _wire2api_media_device_kind(dynamic raw) {
  return MediaDeviceKind.values[raw];
}

MediaStreamTrack_ _wire2api_media_stream_track(dynamic raw) {
  final arr = raw as List<dynamic>;
  if (arr.length != 4)
    throw Exception('unexpected arr length: expect 4 but see ${arr.length}');
  return MediaStreamTrack_(
    id: _wire2api_u64(arr[0]),
    label: _wire2api_String(arr[1]),
    kind: _wire2api_media_type(arr[2]),
    enabled: _wire2api_bool(arr[3]),
  );
}

MediaType _wire2api_media_type(dynamic raw) {
  return MediaType.values[raw];
}

int _wire2api_u64(dynamic raw) {
  return raw as int;
}

int _wire2api_u8(dynamic raw) {
  return raw as int;
}

Uint8List _wire2api_uint_8_list(dynamic raw) {
  return raw as Uint8List;
}

void _wire2api_unit(dynamic raw) {
  return;
}

// ignore_for_file: camel_case_types, non_constant_identifier_names, avoid_positional_boolean_parameters, annotate_overrides, constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.

/// generated by flutter_rust_bridge
class FlutterWebrtcNativeWire implements FlutterRustBridgeWireBase {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  FlutterWebrtcNativeWire(ffi.DynamicLibrary dynamicLibrary)
      : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  FlutterWebrtcNativeWire.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  void wire_webrtc_init(
    int port_,
  ) {
    return _wire_webrtc_init(
      port_,
    );
  }

  late final _wire_webrtc_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_webrtc_init');
  late final _wire_webrtc_init =
      _wire_webrtc_initPtr.asFunction<void Function(int)>();

  void wire_create_video_sink(
    int port_,
    int sink_id,
    int track_id,
    int callback_ptr,
  ) {
    return _wire_create_video_sink(
      port_,
      sink_id,
      track_id,
      callback_ptr,
    );
  }

  late final _wire_create_video_sinkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Int64, ffi.Uint64,
              ffi.Uint64)>>('wire_create_video_sink');
  late final _wire_create_video_sink = _wire_create_video_sinkPtr
      .asFunction<void Function(int, int, int, int)>();

  void wire_dispose_video_sink(
    int port_,
    int sink_id,
  ) {
    return _wire_dispose_video_sink(
      port_,
      sink_id,
    );
  }

  late final _wire_dispose_video_sinkPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Int64)>>(
          'wire_dispose_video_sink');
  late final _wire_dispose_video_sink =
      _wire_dispose_video_sinkPtr.asFunction<void Function(int, int)>();

  void wire_enumerate_devices(
    int port_,
  ) {
    return _wire_enumerate_devices(
      port_,
    );
  }

  late final _wire_enumerate_devicesPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_enumerate_devices');
  late final _wire_enumerate_devices =
      _wire_enumerate_devicesPtr.asFunction<void Function(int)>();

  void wire_get_media(
    int port_,
    ffi.Pointer<wire_MediaStreamConstraints> constraints,
    bool is_display,
  ) {
    return _wire_get_media(
      port_,
      constraints,
      is_display ? 1 : 0,
    );
  }

  late final _wire_get_mediaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Pointer<wire_MediaStreamConstraints>,
              ffi.Uint8)>>('wire_get_media');
  late final _wire_get_media = _wire_get_mediaPtr.asFunction<
      void Function(int, ffi.Pointer<wire_MediaStreamConstraints>, int)>();

  ffi.Pointer<wire_AudioConstraints> new_box_autoadd_audio_constraints() {
    return _new_box_autoadd_audio_constraints();
  }

  late final _new_box_autoadd_audio_constraintsPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<wire_AudioConstraints> Function()>>(
      'new_box_autoadd_audio_constraints');
  late final _new_box_autoadd_audio_constraints =
      _new_box_autoadd_audio_constraintsPtr
          .asFunction<ffi.Pointer<wire_AudioConstraints> Function()>();

  ffi.Pointer<wire_MediaStreamConstraints>
      new_box_autoadd_media_stream_constraints() {
    return _new_box_autoadd_media_stream_constraints();
  }

  late final _new_box_autoadd_media_stream_constraintsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<wire_MediaStreamConstraints>
              Function()>>('new_box_autoadd_media_stream_constraints');
  late final _new_box_autoadd_media_stream_constraints =
      _new_box_autoadd_media_stream_constraintsPtr
          .asFunction<ffi.Pointer<wire_MediaStreamConstraints> Function()>();

  ffi.Pointer<wire_VideoConstraints> new_box_autoadd_video_constraints() {
    return _new_box_autoadd_video_constraints();
  }

  late final _new_box_autoadd_video_constraintsPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<wire_VideoConstraints> Function()>>(
      'new_box_autoadd_video_constraints');
  late final _new_box_autoadd_video_constraints =
      _new_box_autoadd_video_constraintsPtr
          .asFunction<ffi.Pointer<wire_VideoConstraints> Function()>();

  ffi.Pointer<wire_uint_8_list> new_uint_8_list(
    int len,
  ) {
    return _new_uint_8_list(
      len,
    );
  }

  late final _new_uint_8_listPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<wire_uint_8_list> Function(
              ffi.Int32)>>('new_uint_8_list');
  late final _new_uint_8_list = _new_uint_8_listPtr
      .asFunction<ffi.Pointer<wire_uint_8_list> Function(int)>();

  void free_WireSyncReturnStruct(
    WireSyncReturnStruct val,
  ) {
    return _free_WireSyncReturnStruct(
      val,
    );
  }

  late final _free_WireSyncReturnStructPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(WireSyncReturnStruct)>>(
          'free_WireSyncReturnStruct');
  late final _free_WireSyncReturnStruct = _free_WireSyncReturnStructPtr
      .asFunction<void Function(WireSyncReturnStruct)>();

  void store_dart_post_cobject(
    DartPostCObjectFnType ptr,
  ) {
    return _store_dart_post_cobject(
      ptr,
    );
  }

  late final _store_dart_post_cobjectPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(DartPostCObjectFnType)>>(
          'store_dart_post_cobject');
  late final _store_dart_post_cobject = _store_dart_post_cobjectPtr
      .asFunction<void Function(DartPostCObjectFnType)>();
}

class wire_uint_8_list extends ffi.Struct {
  external ffi.Pointer<ffi.Uint8> ptr;

  @ffi.Int32()
  external int len;
}

class wire_AudioConstraints extends ffi.Struct {
  @ffi.Uint8()
  external int required;

  external ffi.Pointer<wire_uint_8_list> device_id;
}

class wire_VideoConstraints extends ffi.Struct {
  external ffi.Pointer<wire_uint_8_list> device_id;

  @ffi.Uint32()
  external int width;

  @ffi.Uint32()
  external int height;

  @ffi.Uint32()
  external int frame_rate;
}

class wire_MediaStreamConstraints extends ffi.Struct {
  external ffi.Pointer<wire_AudioConstraints> audio;

  external ffi.Pointer<wire_VideoConstraints> video;
}

typedef DartPostCObjectFnType = ffi.Pointer<
    ffi.NativeFunction<ffi.Uint8 Function(DartPort, ffi.Pointer<ffi.Void>)>>;
typedef DartPort = ffi.Int64;
