// AUTO GENERATED FILE, DO NOT EDIT.
// Generated by `flutter_rust_bridge`@ 1.62.1.
// ignore_for_file: non_constant_identifier_names, unused_element, duplicate_ignore, directives_ordering, curly_braces_in_flow_control_structures, unnecessary_lambdas, slash_for_doc_comments, prefer_const_literals_to_create_immutables, implicit_dynamic_list_literal, duplicate_import, unused_import, unnecessary_import, prefer_single_quotes, prefer_const_constructors, use_super_parameters, always_use_package_imports, annotate_overrides, invalid_use_of_protected_member, constant_identifier_names, invalid_use_of_internal_member

import 'dart:convert';
import 'dart:async';
import 'package:meta/meta.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;

import 'dart:ffi' as ffi;

part 'bridge.g.freezed.dart';

abstract class FlutterWebrtcNative {
  /// Configures media acquisition to use fake devices instead of actual camera
  /// and microphone.
  Future<void> enableFakeMedia({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kEnableFakeMediaConstMeta;

  /// Indicates whether application is configured to use fake media devices.
  Future<bool> isFakeMedia({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kIsFakeMediaConstMeta;

  /// Returns a list of all available media input and output devices, such as
  /// microphones, cameras, headsets, and so forth.
  Future<List<MediaDeviceInfo>> enumerateDevices({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kEnumerateDevicesConstMeta;

  /// Enumerates possible system audio sources.
  Future<List<AudioSourceInfo>> enumerateSystemAudioSource({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kEnumerateSystemAudioSourceConstMeta;

  /// Returns a list of all available displays that can be used for screen
  /// capturing.
  Future<List<MediaDisplayInfo>> enumerateDisplays({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kEnumerateDisplaysConstMeta;

  /// Creates a new [`PeerConnection`] and returns its ID.
  Stream<PeerConnectionEvent> createPeerConnection(
      {required RtcConfiguration configuration, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kCreatePeerConnectionConstMeta;

  /// Initiates the creation of an SDP offer for the purpose of starting a new
  /// WebRTC connection to a remote peer.
  Future<RtcSessionDescription> createOffer(
      {required int peerId,
      required bool voiceActivityDetection,
      required bool iceRestart,
      required bool useRtpMux,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kCreateOfferConstMeta;

  /// Creates an SDP answer to an offer received from a remote peer during an
  /// offer/answer negotiation of a WebRTC connection.
  Future<RtcSessionDescription> createAnswer(
      {required int peerId,
      required bool voiceActivityDetection,
      required bool iceRestart,
      required bool useRtpMux,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kCreateAnswerConstMeta;

  /// Changes the local description associated with the connection.
  Future<void> setLocalDescription(
      {required int peerId,
      required SdpType kind,
      required String sdp,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetLocalDescriptionConstMeta;

  /// Sets the specified session description as the remote peer's current offer or
  /// answer.
  Future<void> setRemoteDescription(
      {required int peerId,
      required SdpType kind,
      required String sdp,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetRemoteDescriptionConstMeta;

  /// Creates a new [`RtcRtpTransceiver`] and adds it to the set of transceivers
  /// of the specified [`PeerConnection`].
  Future<RtcRtpTransceiver> addTransceiver(
      {required int peerId,
      required MediaType mediaType,
      required RtpTransceiverDirection direction,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kAddTransceiverConstMeta;

  /// Returns a sequence of [`RtcRtpTransceiver`] objects representing the RTP
  /// transceivers currently attached to the specified [`PeerConnection`].
  Future<List<RtcRtpTransceiver>> getTransceivers(
      {required int peerId, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kGetTransceiversConstMeta;

  /// Changes the preferred `direction` of the specified [`RtcRtpTransceiver`].
  Future<void> setTransceiverDirection(
      {required int peerId,
      required int transceiverIndex,
      required RtpTransceiverDirection direction,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetTransceiverDirectionConstMeta;

  /// Changes the receive direction of the specified [`RtcRtpTransceiver`].
  Future<void> setTransceiverRecv(
      {required int peerId,
      required int transceiverIndex,
      required bool recv,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetTransceiverRecvConstMeta;

  /// Changes the send direction of the specified [`RtcRtpTransceiver`].
  Future<void> setTransceiverSend(
      {required int peerId,
      required int transceiverIndex,
      required bool send,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetTransceiverSendConstMeta;

  /// Returns the [negotiated media ID (mid)][1] of the specified
  /// [`RtcRtpTransceiver`].
  ///
  /// [1]: https://w3.org/TR/webrtc#dfn-media-stream-identification-tag
  Future<String?> getTransceiverMid(
      {required int peerId, required int transceiverIndex, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kGetTransceiverMidConstMeta;

  /// Returns the preferred direction of the specified [`RtcRtpTransceiver`].
  Future<RtpTransceiverDirection> getTransceiverDirection(
      {required int peerId, required int transceiverIndex, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kGetTransceiverDirectionConstMeta;

  /// Returns [`RtcStats`] of the [`PeerConnection`] by its ID.
  Future<List<RtcStats>> getPeerStats({required int peerId, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kGetPeerStatsConstMeta;

  /// Irreversibly marks the specified [`RtcRtpTransceiver`] as stopping, unless
  /// it's already stopped.
  ///
  /// This will immediately cause the transceiver's sender to no longer send, and
  /// its receiver to no longer receive.
  Future<void> stopTransceiver(
      {required int peerId, required int transceiverIndex, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kStopTransceiverConstMeta;

  /// Replaces the specified [`AudioTrack`] (or [`VideoTrack`]) on the
  /// [`sys::Transceiver`]'s `sender`.
  Future<void> senderReplaceTrack(
      {required int peerId,
      required int transceiverIndex,
      String? trackId,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSenderReplaceTrackConstMeta;

  /// Adds the new ICE `candidate` to the given [`PeerConnection`].
  Future<void> addIceCandidate(
      {required int peerId,
      required String candidate,
      required String sdpMid,
      required int sdpMlineIndex,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kAddIceCandidateConstMeta;

  /// Tells the [`PeerConnection`] that ICE should be restarted.
  Future<void> restartIce({required int peerId, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kRestartIceConstMeta;

  /// Closes the [`PeerConnection`].
  Future<void> disposePeerConnection({required int peerId, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kDisposePeerConnectionConstMeta;

  /// Creates a [`MediaStream`] with tracks according to provided
  /// [`MediaStreamConstraints`].
  Future<GetMediaResult> getMedia(
      {required MediaStreamConstraints constraints, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kGetMediaConstMeta;

  /// Sets the specified `audio playout` device.
  Future<void> setAudioPlayoutDevice({required String deviceId, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetAudioPlayoutDeviceConstMeta;

  /// Indicates whether the microphone is available to set volume.
  Future<bool> microphoneVolumeIsAvailable({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kMicrophoneVolumeIsAvailableConstMeta;

  /// Sets the microphone system volume according to the specified `level` in
  /// percents.
  ///
  /// Valid values range is `[0; 100]`.
  Future<void> setMicrophoneVolume({required int level, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetMicrophoneVolumeConstMeta;

  /// Returns the current level of the microphone volume in `[0; 100]` range.
  Future<int> microphoneVolume({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kMicrophoneVolumeConstMeta;

  /// Disposes the specified [`MediaStreamTrack`].
  Future<void> disposeTrack(
      {required String trackId, required MediaType kind, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kDisposeTrackConstMeta;

  /// Returns the [readyState][0] property of the [`MediaStreamTrack`] by its ID
  /// and [`MediaType`].
  ///
  /// [0]: https://w3.org/TR/mediacapture-streams#dfn-readystate
  Future<TrackState> trackState(
      {required String trackId, required MediaType kind, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kTrackStateConstMeta;

  /// Changes the [enabled][1] property of the [`MediaStreamTrack`] by its ID and
  /// [`MediaType`].
  ///
  /// [1]: https://w3.org/TR/mediacapture-streams#track-enabled
  Future<void> setTrackEnabled(
      {required String trackId,
      required MediaType kind,
      required bool enabled,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetTrackEnabledConstMeta;

  /// Clones the specified [`MediaStreamTrack`].
  Future<MediaStreamTrack> cloneTrack(
      {required String trackId, required MediaType kind, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kCloneTrackConstMeta;

  /// Sets the volume of the system audio capture.
  Future<void> setSystemAudioVolume({required double level, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetSystemAudioVolumeConstMeta;

  /// Returns the current volume of the system audio capture.
  Future<double> systemAudioVolume({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSystemAudioVolumeConstMeta;

  /// Registers an observer to the [`MediaStreamTrack`] events.
  Stream<TrackEvent> registerTrackObserver(
      {required String trackId, required MediaType kind, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kRegisterTrackObserverConstMeta;

  /// Sets the provided [`OnDeviceChangeCallback`] as the callback to be called
  /// whenever a set of available media devices changes.
  ///
  /// Only one callback can be set at a time, so the previous one will be dropped,
  /// if any.
  Stream<void> setOnDeviceChanged({dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetOnDeviceChangedConstMeta;

  Stream<double> setOnAudioLevelChanged(
      {required String trackId, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kSetOnAudioLevelChangedConstMeta;

  /// Creates a new [`VideoSink`] attached to the specified video track.
  ///
  /// `callback_ptr` argument should be a pointer to an [`UniquePtr`] pointing to
  /// an [`OnFrameCallbackInterface`].
  Future<void> createVideoSink(
      {required int sinkId,
      required String trackId,
      required int callbackPtr,
      dynamic hint});

  FlutterRustBridgeTaskConstMeta get kCreateVideoSinkConstMeta;

  /// Destroys the [`VideoSink`] by the provided ID.
  Future<void> disposeVideoSink({required int sinkId, dynamic hint});

  FlutterRustBridgeTaskConstMeta get kDisposeVideoSinkConstMeta;
}

/// Nature and settings of the audio [`MediaStreamTrack`] returned by
/// [`Webrtc::get_users_media()`].
class AudioConstraints {
  /// Identifier of the device generating the content of the
  /// [`MediaStreamTrack`].
  ///
  /// First device will be chosen if an empty [`String`] is provided.
  ///
  /// **NOTE**: There can be only one active recording device at a time, so
  ///           changing device will affect all previously obtained audio
  ///           tracks.
  final String? deviceId;

  /// Identifier of the system audio source generating the content of the
  /// [`MediaStreamTrack`].
  final int? systemId;

  AudioConstraints({
    this.deviceId,
    this.systemId,
  });
}

/// Information about system audio source.
class AudioSourceInfo {
  /// Unique id of system audio source.
  final int id;

  /// Title of system audio source.
  final String title;

  AudioSourceInfo({
    required this.id,
    required this.title,
  });
}

/// [RTCBundlePolicy][1] representation.
///
/// Affects which media tracks are negotiated if the remote endpoint is not
/// bundle-aware, and what ICE candidates are gathered. If the remote endpoint
/// is bundle-aware, all media tracks and data channels are bundled onto the
/// same transport.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy
enum BundlePolicy {
  /// [RTCBundlePolicy.balanced][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-balanced
  Balanced,

  /// [RTCBundlePolicy.max-bundle][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-max-bundle
  MaxBundle,

  /// [RTCBundlePolicy.max-compat][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-max-compat
  MaxCompat,
}

/// [RTCIceCandidateType] represents the type of the ICE candidate, as defined
/// in [Section 15.1 of RFC 5245][1].
///
/// [RTCIceCandidateType]: https://w3.org/TR/webrtc#rtcicecandidatetype-enum
/// [1]: https://tools.ietf.org/html/rfc5245#section-15.1
enum CandidateType {
  /// Host candidate, as defined in [Section 4.1.1.1 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-4.1.1.1
  Host,

  /// Server reflexive candidate, as defined in
  /// [Section 4.1.1.2 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-4.1.1.2
  Srflx,

  /// Peer reflexive candidate, as defined in
  /// [Section 4.1.1.2 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-4.1.1.2
  Prflx,

  /// Relay candidate, as defined in [Section 7.1.3.2.1 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-7.1.3.2.1
  Relay,
}

@freezed
class GetMediaError with _$GetMediaError {
  /// Could not acquire audio track.
  const factory GetMediaError.audio(
    String field0,
  ) = GetMediaError_Audio;

  /// Could not acquire video track.
  const factory GetMediaError.video(
    String field0,
  ) = GetMediaError_Video;
}

@freezed
class GetMediaResult with _$GetMediaResult {
  /// Requested media tracks.
  const factory GetMediaResult.ok(
    List<MediaStreamTrack> field0,
  ) = GetMediaResult_Ok;

  /// Failed to get requested media.
  const factory GetMediaResult.err(
    GetMediaError field0,
  ) = GetMediaResult_Err;
}

/// Properties of a `candidate` in [Section 15.1 of RFC 5245][1].
/// It corresponds to an [RTCIceTransport] object.
///
/// [`RtcIceCandidateStats::Local`] or [`RtcIceCandidateStats::Remote`] variant.
///
/// [Full doc on W3C][2].
///
/// [RTCIceTransport]: https://w3.org/TR/webrtc#dom-rtcicetransport
/// [1]: https://tools.ietf.org/html/rfc5245#section-15.1
/// [2]: https://w3.org/TR/webrtc-stats#icecandidate-dict%2A
class IceCandidateStats {
  /// Unique ID that is associated to the object that was inspected to produce
  /// the [RTCTransportStats][1] associated with this candidate.
  ///
  /// [1]: https://w3.org/TR/webrtc-stats#transportstats-dict%2A
  final String? transportId;

  /// Address of the candidate, allowing for IPv4 addresses, IPv6 addresses,
  /// and fully qualified domain names (FQDNs).
  final String? address;

  /// Port number of the candidate.
  final int? port;

  /// Valid values for transport is one of `udp` and `tcp`.
  final Protocol protocol;

  /// Type of the ICE candidate.
  final CandidateType candidateType;

  /// Calculated as defined in [Section 15.1 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-15.1
  final int? priority;

  /// For local candidates this is the URL of the ICE server from which the
  /// candidate was obtained. It is the same as the [url][2] surfaced in the
  /// [RTCPeerConnectionIceEvent][1].
  ///
  /// [`None`] for remote candidates.
  ///
  /// [1]: https://w3.org/TR/webrtc#rtcpeerconnectioniceevent
  /// [2]: https://w3.org/TR/webrtc#dom-rtcpeerconnectioniceevent-url
  final String? url;

  /// Protocol used by the endpoint to communicate with the TURN server.
  ///
  /// Only present for local candidates.
  final Protocol? relayProtocol;

  IceCandidateStats({
    this.transportId,
    this.address,
    this.port,
    required this.protocol,
    required this.candidateType,
    this.priority,
    this.url,
    this.relayProtocol,
  });
}

/// [RTCIceConnectionState][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate
enum IceConnectionState {
  /// [RTCIceConnectionState.new][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-new
  New,

  /// [RTCIceConnectionState.checking][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-checking
  Checking,

  /// [RTCIceConnectionState.connected][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-connected
  Connected,

  /// [RTCIceConnectionState.completed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-completed
  Completed,

  /// [RTCIceConnectionState.failed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-failed
  Failed,

  /// [RTCIceConnectionState.disconnected][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-disconnected
  Disconnected,

  /// [RTCIceConnectionState.closed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-closed
  Closed,
}

/// [RTCIceGatheringState][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate
enum IceGatheringState {
  /// [RTCIceGatheringState.new][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-new
  New,

  /// [RTCIceGatheringState.gathering][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-gathering
  Gathering,

  /// [RTCIceGatheringState.complete][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-complete
  Complete,
}

/// Variants of [ICE roles][1].
///
/// More info in the [RFC 5245].
///
/// [RFC 5245]: https://tools.ietf.org/html/rfc5245
/// [1]: https://w3.org/TR/webrtc#dom-icetransport-role
enum IceRole {
  /// Agent whose role as defined by [Section 3 in RFC 5245][1], has not yet
  /// been determined.
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-3
  Unknown,

  /// Controlling agent as defined by [Section 3 in RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-3
  Controlling,

  /// Controlled agent as defined by [Section 3 in RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-3
  Controlled,
}

/// [RTCIceTransportPolicy][1] representation.
///
/// It defines an ICE candidate policy the [ICE Agent][2] uses to surface
/// the permitted candidates to the application. Only these candidates will
/// be used for connectivity checks.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy
/// [2]: https://w3.org/TR/webrtc#dfn-ice-agent
enum IceTransportsType {
  /// [RTCIceTransportPolicy.all][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy-all
  All,

  /// [RTCIceTransportPolicy.relay][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy-relay
  Relay,

  /// ICE Agent can't use `typ host` candidates when this value is specified.
  ///
  /// Non-spec-compliant variant.
  NoHost,

  /// No ICE candidate offered.
  None,
}

/// Information describing a single media input or output device.
class MediaDeviceInfo {
  /// Unique identifier for the represented device.
  final String deviceId;

  /// Kind of the represented device.
  final MediaDeviceKind kind;

  /// Label describing the represented device.
  final String label;

  MediaDeviceInfo({
    required this.deviceId,
    required this.kind,
    required this.label,
  });
}

/// Possible kinds of media devices.
enum MediaDeviceKind {
  /// Audio input device (for example, a microphone).
  AudioInput,

  /// Audio output device (for example, a pair of headphones).
  AudioOutput,

  /// Video input device (for example, a webcam).
  VideoInput,
}

/// Information describing a display.
class MediaDisplayInfo {
  /// Unique identifier of the device representing the display.
  final String deviceId;

  /// Title describing the represented display.
  final String? title;

  MediaDisplayInfo({
    required this.deviceId,
    this.title,
  });
}

/// [MediaStreamConstraints], used to instruct what sort of
/// [`MediaStreamTrack`]s to include in the [`MediaStream`] returned by
/// [`Webrtc::get_users_media()`].
///
/// [1]: https://w3.org/TR/mediacapture-streams#dom-mediastreamconstraints
class MediaStreamConstraints {
  /// Specifies the nature and settings of the audio [`MediaStreamTrack`].
  final AudioConstraints? audio;

  /// Specifies the nature and settings of the video [`MediaStreamTrack`].
  final VideoConstraints? video;

  MediaStreamConstraints({
    this.audio,
    this.video,
  });
}

/// Representation of a single media track within a [`MediaStream`].
///
/// Typically, these are audio or video tracks, but other track types may exist
/// as well.
class MediaStreamTrack {
  /// Unique identifier (GUID) of this [`MediaStreamTrack`].
  final String id;

  /// Label identifying the track source, as in "internal microphone".
  final String deviceId;

  /// [`MediaType`] of this [`MediaStreamTrack`].
  final MediaType kind;

  /// Indicator whether this [`MediaStreamTrack`] is allowed to render the
  /// source stream.
  ///
  /// This can be used to intentionally mute a track.
  final bool enabled;

  MediaStreamTrack({
    required this.id,
    required this.deviceId,
    required this.kind,
    required this.enabled,
  });
}

/// Possible media types of a [`MediaStreamTrack`].
enum MediaType {
  /// Audio [`MediaStreamTrack`].
  Audio,

  /// Video [`MediaStreamTrack`].
  Video,
}

@freezed
class PeerConnectionEvent with _$PeerConnectionEvent {
  /// [`PeerConnection`] has been created.
  const factory PeerConnectionEvent.peerCreated({
    /// ID of the created [`PeerConnection`].
    required int id,
  }) = PeerConnectionEvent_PeerCreated;

  /// [RTCIceCandidate][1] has been discovered.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
  const factory PeerConnectionEvent.iceCandidate({
    /// Media stream "identification-tag" defined in [RFC 5888] for the
    /// media component the discovered [RTCIceCandidate][1] is associated
    /// with.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    /// [RFC 5888]: https://tools.ietf.org/html/rfc5888
    required String sdpMid,

    /// Index (starting at zero) of the media description in the SDP this
    /// [RTCIceCandidate][1] is associated with.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    required int sdpMlineIndex,

    /// Candidate-attribute as defined in Section 15.1 of [RFC 5245].
    ///
    /// If this [RTCIceCandidate][1] represents an end-of-candidates
    /// indication or a peer reflexive remote candidate, candidate is an
    /// empty string.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    /// [RFC 5245]: https://tools.ietf.org/html/rfc5245
    required String candidate,
  }) = PeerConnectionEvent_IceCandidate;

  /// [`PeerConnection`]'s ICE gathering state has changed.
  const factory PeerConnectionEvent.iceGatheringStateChange(
    IceGatheringState field0,
  ) = PeerConnectionEvent_IceGatheringStateChange;

  /// Failure occurred when gathering [RTCIceCandidate][1].
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
  const factory PeerConnectionEvent.iceCandidateError({
    /// Local IP address used to communicate with the STUN or TURN server.
    required String address,

    /// Port used to communicate with the STUN or TURN server.
    required int port,

    /// STUN or TURN URL identifying the STUN or TURN server for which the
    /// failure occurred.
    required String url,

    /// Numeric STUN error code returned by the STUN or TURN server
    /// [`STUN-PARAMETERS`][1].
    ///
    /// If no host candidate can reach the server, it will be set to the
    /// value `701` which is outside the STUN error code range.
    ///
    /// [1]: https://tinyurl.com/stun-parameters-6
    required int errorCode,

    /// STUN reason text returned by the STUN or TURN server
    /// [`STUN-PARAMETERS`][1].
    ///
    /// If the server could not be reached, it will be set to an
    /// implementation-specific value providing details about the error.
    ///
    /// [1]: https://tinyurl.com/stun-parameters-6
    required String errorText,
  }) = PeerConnectionEvent_IceCandidateError;

  /// Negotiation or renegotiation of the [`PeerConnection`] needs to be
  /// performed.
  const factory PeerConnectionEvent.negotiationNeeded() =
      PeerConnectionEvent_NegotiationNeeded;

  /// [`PeerConnection`]'s [`SignalingState`] has been changed.
  const factory PeerConnectionEvent.signallingChange(
    SignalingState field0,
  ) = PeerConnectionEvent_SignallingChange;

  /// [`PeerConnection`]'s [`IceConnectionState`] has been changed.
  const factory PeerConnectionEvent.iceConnectionStateChange(
    IceConnectionState field0,
  ) = PeerConnectionEvent_IceConnectionStateChange;

  /// [`PeerConnection`]'s [`PeerConnectionState`] has been changed.
  const factory PeerConnectionEvent.connectionStateChange(
    PeerConnectionState field0,
  ) = PeerConnectionEvent_ConnectionStateChange;

  /// New incoming media has been negotiated.
  const factory PeerConnectionEvent.track(
    RtcTrackEvent field0,
  ) = PeerConnectionEvent_Track;
}

/// Indicator of the current state of a [`PeerConnection`].
enum PeerConnectionState {
  /// At least one of the connection's ICE transports is in the new state,
  /// and none of them are in one of the following states: `connecting`,
  /// `checking`, `failed`, `disconnected`, or all of the connection's
  /// transports are in the `closed` state.
  New,

  /// One or more of the ICE transports are currently in the process of
  /// establishing a connection. That is, their [`IceConnectionState`] is
  /// either [`IceConnectionState::Checking`] or
  /// [`IceConnectionState::Connected`], and no transports are in the
  /// `failed` state.
  Connecting,

  /// Every ICE transport used by the connection is either in use (state
  /// `connected` or `completed`) or is closed (state `closed`). In addition,
  /// at least one transport is either `connected` or `completed`.
  Connected,

  /// At least one of the ICE transports for the connection is in the
  /// `disconnected` state and none of the other transports are in the state
  /// `failed`, `connecting` or `checking`.
  Disconnected,

  /// One or more of the ICE transports on the connection is in the `failed`
  /// state.
  Failed,

  /// Peer connection is closed.
  Closed,
}

/// Transport protocols used in [WebRTC].
///
/// [WebRTC]: https://w3.org/TR/webrtc
enum Protocol {
  /// [Transmission Control Protocol][1].
  ///
  /// [1]: https://en.wikipedia.org/wiki/Transmission_Control_Protocol
  Tcp,

  /// [User Datagram Protocol][1].
  ///
  /// [1]: https://en.wikipedia.org/wiki/User_Datagram_Protocol
  Udp,
}

/// [`PeerConnection`]'s configuration.
class RtcConfiguration {
  /// [iceTransportPolicy][1] configuration.
  ///
  /// Indicates which candidates the [ICE Agent][2] is allowed to use.
  ///
  /// [1]: https://tinyurl.com/icetransportpolicy
  /// [2]: https://w3.org/TR/webrtc#dfn-ice-agent
  final IceTransportsType iceTransportPolicy;

  /// [bundlePolicy][1] configuration.
  ///
  /// Indicates which media-bundling policy to use when gathering ICE
  /// candidates.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcconfiguration-bundlepolicy
  final BundlePolicy bundlePolicy;

  /// [iceServers][1] configuration.
  ///
  /// An array of objects describing servers available to be used by ICE,
  /// such as STUN and TURN servers.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcconfiguration-iceservers
  final List<RtcIceServer> iceServers;

  RtcConfiguration({
    required this.iceTransportPolicy,
    required this.bundlePolicy,
    required this.iceServers,
  });
}

@freezed
class RtcIceCandidateStats with _$RtcIceCandidateStats {
  /// [`IceCandidateStats`] of local candidate.
  const factory RtcIceCandidateStats.local(
    IceCandidateStats field0,
  ) = RtcIceCandidateStats_Local;

  /// [`IceCandidateStats`] of remote candidate.
  const factory RtcIceCandidateStats.remote(
    IceCandidateStats field0,
  ) = RtcIceCandidateStats_Remote;
}

/// Description of STUN and TURN servers that can be used by an [ICE Agent][1]
/// to establish a connection with a peer.
///
/// [1]: https://w3.org/TR/webrtc#dfn-ice-agent
class RtcIceServer {
  /// STUN or TURN URI(s).
  final List<String> urls;

  /// If this [`RtcIceServer`] object represents a TURN server, then this
  /// attribute specifies the [username][1] to use with that TURN server.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceserver-username
  final String username;

  /// If this [`RtcIceServer`] object represents a TURN server, then this
  /// attribute specifies the [credential][1] to use with that TURN
  /// server.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceserver-credential
  final String credential;

  RtcIceServer({
    required this.urls,
    required this.username,
    required this.credential,
  });
}

@freezed
class RtcInboundRtpStreamMediaType with _$RtcInboundRtpStreamMediaType {
  /// `audio` media type fields.
  const factory RtcInboundRtpStreamMediaType.audio({
    /// Indicator whether the last RTP packet whose frame was delivered to
    /// the [RTCRtpReceiver]'s [MediaStreamTrack][1] for playout contained
    /// voice activity or not based on the presence of the V bit in the
    /// extension header, as defined in [RFC 6464].
    ///
    /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#rtcrtpreceiver-interface
    /// [RFC 6464]: https://tools.ietf.org/html/rfc6464#page-3
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    bool? voiceActivityFlag,

    /// Total number of samples that have been received on this RTP stream.
    /// This includes [concealedSamples].
    ///
    /// [concealedSamples]: https://tinyurl.com/s6c4qe4
    int? totalSamplesReceived,

    /// Total number of samples that are concealed samples.
    ///
    /// A concealed sample is a sample that was replaced with synthesized
    /// samples generated locally before being played out.
    /// Examples of samples that have to be concealed are samples from lost
    /// packets (reported in [packetsLost]) or samples from packets that
    /// arrive too late to be played out (reported in [packetsDiscarded]).
    ///
    /// [packetsLost]: https://tinyurl.com/u2gq965
    /// [packetsDiscarded]: https://tinyurl.com/yx7qyox3
    int? concealedSamples,

    /// Total number of concealed samples inserted that are "silent".
    ///
    /// Playing out silent samples results in silence or comfort noise.
    /// This is a subset of [concealedSamples].
    ///
    /// [concealedSamples]: https://tinyurl.com/s6c4qe4
    int? silentConcealedSamples,

    /// Audio level of the receiving track.
    double? audioLevel,

    /// Audio energy of the receiving track.
    double? totalAudioEnergy,

    /// Audio duration of the receiving track.
    ///
    /// For audio durations of tracks attached locally, see
    /// [RTCAudioSourceStats][1] instead.
    ///
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcaudiosourcestats
    double? totalSamplesDuration,
  }) = RtcInboundRtpStreamMediaType_Audio;

  /// `video` media type fields.
  const factory RtcInboundRtpStreamMediaType.video({
    /// Total number of frames correctly decoded for this RTP stream, i.e.
    /// frames that would be displayed if no frames are dropped.
    int? framesDecoded,

    /// Total number of key frames, such as key frames in VP8 [RFC 6386] or
    /// IDR-frames in H.264 [RFC 6184], successfully decoded for this RTP
    /// media stream.
    ///
    /// This is a subset of [framesDecoded].
    /// [framesDecoded] - [keyFramesDecoded] gives you the number of delta
    /// frames decoded.
    ///
    /// [RFC 6386]: https://w3.org/TR/webrtc-stats#bib-rfc6386
    /// [RFC 6184]: https://w3.org/TR/webrtc-stats#bib-rfc6184
    /// [framesDecoded]: https://tinyurl.com/srfwrwt
    /// [keyFramesDecoded]: https://tinyurl.com/qtdmhtm
    int? keyFramesDecoded,

    /// Width of the last decoded frame.
    ///
    /// Before the first frame is decoded this attribute is missing.
    int? frameWidth,

    /// Height of the last decoded frame.
    ///
    /// Before the first frame is decoded this attribute is missing.
    int? frameHeight,

    /// Sum of the interframe delays in seconds between consecutively
    /// decoded frames, recorded just after a frame has been decoded.
    double? totalInterFrameDelay,

    /// Number of decoded frames in the last second.
    double? framesPerSecond,

    /// Total number of Full Intra Request (FIR) packets sent by this
    /// receiver.
    int? firCount,

    /// Total number of Picture Loss Indication (PLI) packets sent by this
    /// receiver.
    int? pliCount,

    /// Total number of Slice Loss Indication (SLI) packets sent by this
    /// receiver.
    int? sliCount,

    /// Number of concealment events.
    ///
    /// This counter increases every time a concealed sample is synthesized
    /// after a non-concealed sample. That is, multiple consecutive
    /// concealed samples will increase the [concealedSamples] count
    /// multiple times but is a single concealment event.
    ///
    /// [concealedSamples]: https://tinyurl.com/s6c4qe4
    int? concealmentEvents,

    /// Total number of complete frames received on this RTP stream.
    ///
    /// This metric is incremented when the complete frame is received.
    int? framesReceived,
  }) = RtcInboundRtpStreamMediaType_Video;
}

@freezed
class RtcMediaSourceStatsMediaType with _$RtcMediaSourceStatsMediaType {
  /// Video source fields.
  const factory RtcMediaSourceStatsMediaType.rtcVideoSourceStats({
    /// Width (in pixels) of the last frame originating from the source.
    /// Before a frame has been produced this attribute is missing.
    int? width,

    /// Height (in pixels) of the last frame originating from the source.
    /// Before a frame has been produced this attribute is missing.
    int? height,

    /// Total number of frames originating from this source.
    int? frames,

    /// Number of frames originating from the source, measured during the
    /// last second. For the first second of this object's lifetime this
    /// attribute is missing.
    double? framesPerSecond,
  }) = RtcMediaSourceStatsMediaType_RtcVideoSourceStats;

  /// Audio source fields.
  const factory RtcMediaSourceStatsMediaType.rtcAudioSourceStats({
    /// Audio level of the media source.
    double? audioLevel,

    /// Audio energy of the media source.
    double? totalAudioEnergy,

    /// Audio duration of the media source.
    double? totalSamplesDuration,

    /// Only exists when the [MediaStreamTrack][1] is sourced from a
    /// microphone where echo cancellation is applied.
    ///
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    double? echoReturnLoss,

    /// Only exists when the [MediaStreamTrack][1] is sourced from a
    /// microphone where echo cancellation is applied.
    ///
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    double? echoReturnLossEnhancement,
  }) = RtcMediaSourceStatsMediaType_RtcAudioSourceStats;
}

@freezed
class RtcOutboundRtpStreamStatsMediaType
    with _$RtcOutboundRtpStreamStatsMediaType {
  /// `audio` media type fields.
  const factory RtcOutboundRtpStreamStatsMediaType.audio({
    /// Total number of samples that have been sent over the RTP stream.
    int? totalSamplesSent,

    /// Whether the last RTP packet sent contained voice activity or not
    /// based on the presence of the V bit in the extension header.
    bool? voiceActivityFlag,
  }) = RtcOutboundRtpStreamStatsMediaType_Audio;

  /// `video` media type fields.
  const factory RtcOutboundRtpStreamStatsMediaType.video({
    /// Width of the last encoded frame.
    ///
    /// The resolution of the encoded frame may be lower than the media
    /// source (see [RTCVideoSourceStats.width][1]).
    ///
    /// Before the first frame is encoded this attribute is missing.
    ///
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcvideosourcestats-width
    int? frameWidth,

    /// Height of the last encoded frame.
    ///
    /// The resolution of the encoded frame may be lower than the media
    /// source (see [RTCVideoSourceStats.height][1]).
    ///
    /// Before the first frame is encoded this attribute is missing.
    ///
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcvideosourcestats-height
    int? frameHeight,

    /// Number of encoded frames during the last second.
    ///
    /// This may be lower than the media source frame rate (see
    /// [RTCVideoSourceStats.framesPerSecond][1]).
    ///
    /// [1]: https://tinyurl.com/rrmkrfk
    double? framesPerSecond,
  }) = RtcOutboundRtpStreamStatsMediaType_Video;
}

/// Representation of a permanent pair of an [RTCRtpSender] and an
/// [RTCRtpReceiver], along with some shared state.
///
/// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
/// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
class RtcRtpTransceiver {
  /// ID of the [`PeerConnection`] that this [`RtcRtpTransceiver`] belongs to.
  final int peerId;

  /// ID of this [`RtcRtpTransceiver`].
  ///
  /// It's not unique across all possible [`RtcRtpTransceiver`]s, but only
  /// within a specific peer.
  final int index;

  /// [Negotiated media ID (mid)][1] which the local and remote peers have
  /// agreed upon to uniquely identify the [`MediaStream`]'s pairing of
  /// sender and receiver.
  ///
  /// [1]: https://w3.org/TR/webrtc#dfn-media-stream-identification-tag
  final String? mid;

  /// Preferred [`direction`][1] of this [`RtcRtpTransceiver`].
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver-direction
  final RtpTransceiverDirection direction;

  RtcRtpTransceiver({
    required this.peerId,
    required this.index,
    this.mid,
    required this.direction,
  });
}

/// [RTCSessionDescription] representation.
///
/// [RTCSessionDescription]: https://w3.org/TR/webrtc#dom-rtcsessiondescription
class RtcSessionDescription {
  /// String representation of the SDP.
  final String sdp;

  /// Type of this [`RtcSessionDescription`].
  final SdpType kind;

  RtcSessionDescription({
    required this.sdp,
    required this.kind,
  });
}

/// Represents the [stats object] constructed by inspecting a specific
/// [monitored object].
///
/// [Full doc on W3C][1].
///
/// [stats object]: https://w3.org/TR/webrtc-stats#dfn-stats-object
/// [monitored object]: https://w3.org/TR/webrtc-stats#dfn-monitored-object
/// [1]: https://w3.org/TR/webrtc#rtcstats-dictionary
class RtcStats {
  /// Unique ID that is associated with the object that was inspected to
  /// produce this [RTCStats] object.
  ///
  /// [RTCStats]: https://w3.org/TR/webrtc#dom-rtcstats
  final String id;

  /// Timestamp associated with this object.
  ///
  /// The time is relative to the UNIX epoch (Jan 1, 1970, UTC).
  ///
  /// For statistics that came from a remote source (e.g., from received RTCP
  /// packets), timestamp represents the time at which the information
  /// arrived at the local endpoint. The remote timestamp can be found in an
  /// additional field in an [`RtcStats`]-derived dictionary, if applicable.
  final int timestampUs;

  /// Actual stats of these [`RtcStats`].
  ///
  /// All possible stats are described in the [`RtcStatsType`] enum.
  final RtcStatsType kind;

  RtcStats({
    required this.id,
    required this.timestampUs,
    required this.kind,
  });
}

/// Each candidate pair in the check list has a foundation and a state.
/// The foundation is the combination of the foundations of the local and remote
/// candidates in the pair. The state is assigned once the check list for each
/// media stream has been computed. There are five potential values that the
/// state can have.
enum RtcStatsIceCandidatePairState {
  /// Check for this pair hasn't been performed, and it can't yet be performed
  /// until some other check succeeds, allowing this pair to unfreeze and move
  /// into the [`RtcStatsIceCandidatePairState::Waiting`] state.
  Frozen,

  /// Check has not been performed for this pair, and can be performed as soon
  /// as it is the highest-priority Waiting pair on the check list.
  Waiting,

  /// Check has been sent for this pair, but the transaction is in progress.
  InProgress,

  /// Check for this pair was already done and failed, either never producing
  /// any response or producing an unrecoverable failure response.
  Failed,

  /// Check for this pair was already done and produced a successful result.
  Succeeded,
}

@freezed
class RtcStatsType with _$RtcStatsType {
  /// Statistics for the media produced by a [MediaStreamTrack][1] that is
  /// currently attached to an [RTCRtpSender]. This reflects the media that is
  /// fed to the encoder after [getUserMedia()] constraints have been applied
  /// (i.e. not the raw media produced by the camera).
  ///
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#rtcrtpsender-interface
  /// [getUserMedia()]: https://tinyurl.com/sngpyr6
  /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
  const factory RtcStatsType.rtcMediaSourceStats({
    /// Value of the [MediaStreamTrack][1]'s ID attribute.
    ///
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    String? trackIdentifier,

    /// Fields which should be in these [`RtcStats`] based on their `kind`.
    required RtcMediaSourceStatsMediaType kind,
  }) = RtcStatsType_RtcMediaSourceStats;

  /// ICE remote candidate statistics related to the [RTCIceTransport]
  /// objects.
  ///
  /// A remote candidate is [deleted][1] when the [RTCIceTransport] does an
  /// ICE restart, and the candidate is no longer a member of any non-deleted
  /// candidate pair.
  ///
  /// [RTCIceTransport]: https://w3.org/TR/webrtc#dom-rtcicetransport
  /// [1]: https://w3.org/TR/webrtc-stats#dfn-deleted
  const factory RtcStatsType.rtcIceCandidateStats(
    RtcIceCandidateStats field0,
  ) = RtcStatsType_RtcIceCandidateStats;

  /// Statistics for an outbound [RTP] stream that is currently sent with
  /// [RTCPeerConnection] object.
  ///
  /// When there are multiple [RTP] streams connected to the same sender, such
  /// as when using simulcast or RTX, there will be one
  /// [RTCOutboundRtpStreamStats][5] per RTP stream, with distinct values of
  /// the [SSRC] attribute, and all these senders will have a reference to the
  /// same "sender" object (of type [RTCAudioSenderStats][1] or
  /// [RTCVideoSenderStats][2]) and "track" object (of type
  /// [RTCSenderAudioTrackAttachmentStats][3] or
  /// [RTCSenderVideoTrackAttachmentStats][4]).
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
  /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcaudiosenderstats
  /// [2]: https://w3.org/TR/webrtc-stats#dom-rtcvideosenderstats
  /// [3]: https://tinyurl.com/sefa5z4
  /// [4]: https://tinyurl.com/rkuvpl4
  /// [5]: https://w3.org/TR/webrtc-stats#dom-rtcoutboundrtpstreamstats
  const factory RtcStatsType.rtcOutboundRtpStreamStats({
    /// ID of the stats object representing the current track attachment to
    /// the sender of the stream.
    String? trackId,

    /// Fields which should be in these [`RtcStats`] based on their
    /// `media_type`.
    required RtcOutboundRtpStreamStatsMediaType mediaType,

    /// Total number of bytes sent for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? bytesSent,

    /// Total number of RTP packets sent for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? packetsSent,

    /// ID of the stats object representing the track currently attached to
    /// the sender of the stream.
    String? mediaSourceId,
  }) = RtcStatsType_RtcOutboundRtpStreamStats;

  /// Statistics for an inbound [RTP] stream that is currently received with
  /// [RTCPeerConnection] object.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcInboundRtpStreamStats({
    /// ID of the stats object representing the receiving track.
    String? remoteId,

    /// Total number of bytes received for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? bytesReceived,

    /// Total number of RTP data packets received for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? packetsReceived,

    /// Total number of RTP data packets for this [SSRC] that have been lost
    /// since the beginning of reception.
    ///
    /// This number is defined to be the number of packets expected less the
    /// number of packets actually received, where the number of packets
    /// received includes any which are late or duplicates. Thus, packets
    /// that arrive late are not counted as lost, and the loss
    /// **may be negative** if there are duplicates.
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? packetsLost,

    /// Packet jitter measured in seconds for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    double? jitter,

    /// Total number of seconds that have been spent decoding the
    /// [framesDecoded] frames of the stream.
    ///
    /// The average decode time can be calculated by dividing this value
    /// with [framesDecoded]. The time it takes to decode one frame is the
    /// time passed between feeding the decoder a frame and the decoder
    /// returning decoded data for that frame.
    ///
    /// [framesDecoded]: https://tinyurl.com/srfwrwt
    double? totalDecodeTime,

    /// Total number of audio samples or video frames that have come out of
    /// the jitter buffer (increasing [jitterBufferDelay]).
    ///
    /// [jitterBufferDelay]: https://tinyurl.com/qvoojt5
    int? jitterBufferEmittedCount,

    /// Fields which should be in these [`RtcStats`] based on their
    /// `media_type`.
    RtcInboundRtpStreamMediaType? mediaType,
  }) = RtcStatsType_RtcInboundRtpStreamStats;

  /// ICE candidate pair statistics related to the [RTCIceTransport] objects.
  ///
  /// A candidate pair that is not the current pair for a transport is
  /// [deleted] when the [RTCIceTransport] does an ICE restart, at the time
  /// the state changes to [new].
  ///
  /// The candidate pair that is the current pair for a transport is [deleted]
  /// after an ICE restart when the [RTCIceTransport] switches to using a
  /// candidate pair generated from the new candidates; this time doesn't
  /// correspond to any other externally observable event.
  ///
  /// [deleted]: https://w3.org/TR/webrtc-stats#dfn-deleted
  /// [new]: https://w3.org/TR/webrtc#dom-rtcicetransportstate-new
  /// [RTCIceTransport]: https://w3.org/TR/webrtc#dom-rtcicetransport
  const factory RtcStatsType.rtcIceCandidatePairStats({
    /// State of the checklist for the local and remote candidates in a
    /// pair.
    required RtcStatsIceCandidatePairState state,

    /// Related to updating the nominated flag described in
    /// [Section 7.1.3.2.4 of RFC 5245][1].
    ///
    /// [1]: https://tools.ietf.org/html/rfc5245#section-7.1.3.2.4
    bool? nominated,

    /// Total number of payload bytes sent on this candidate pair, i.e. not
    /// including headers or padding.
    int? bytesSent,

    /// Total number of payload bytes received on this candidate pair, i.e.
    /// not including headers or padding.
    int? bytesReceived,

    /// Sum of all round trip time measurements in seconds since the
    /// beginning of the session, based on STUN connectivity check
    /// [STUN-PATH-CHAR] responses ([responsesReceived][2]), including those
    /// that reply to requests that are sent in order to verify consent
    /// [RFC 7675].
    ///
    /// The average round trip time can be computed from
    /// [totalRoundTripTime][1] by dividing it by [responsesReceived][2].
    ///
    /// [STUN-PATH-CHAR]: https://w3.org/TR/webrtc-stats#bib-stun-path-char
    /// [RFC 7675]: https://tools.ietf.org/html/rfc7675
    /// [1]: https://tinyurl.com/tgr543a
    /// [2]: https://tinyurl.com/r3zo2um
    double? totalRoundTripTime,

    /// Latest round trip time measured in seconds, computed from both STUN
    /// connectivity checks [STUN-PATH-CHAR], including those that are sent
    /// for consent verification [RFC 7675].
    ///
    /// [STUN-PATH-CHAR]: https://w3.org/TR/webrtc-stats#bib-stun-path-char
    /// [RFC 7675]: https://tools.ietf.org/html/rfc7675
    double? currentRoundTripTime,

    /// Calculated by the underlying congestion control by combining the
    /// available bitrate for all the outgoing RTP streams using this
    /// candidate pair. The bitrate measurement does not count the size of
    /// the IP or other transport layers like TCP or UDP. It is similar to
    /// the TIAS defined in [RFC 3890], i.e. it is measured in bits per
    /// second and the bitrate is calculated over a 1 second window.
    ///
    /// Implementations that do not calculate a sender-side estimate MUST
    /// leave this undefined. Additionally, the value MUST be undefined for
    /// candidate pairs that were never used. For pairs in use, the estimate
    /// is normally no lower than the bitrate for the packets sent at
    /// [lastPacketSentTimestamp][1], but might be higher. For candidate
    /// pairs that are not currently in use but were used before,
    /// implementations MUST return undefined.
    ///
    /// [RFC 3890]: https://tools.ietf.org/html/rfc3890
    /// [1]: https://tinyurl.com/rfc72eh
    double? availableOutgoingBitrate,
  }) = RtcStatsType_RtcIceCandidatePairStats;

  /// Transport statistics related to the [RTCPeerConnection] object.
  ///
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcTransportStats({
    /// Total number of packets sent over this transport.
    int? packetsSent,

    /// Total number of packets received on this transport.
    int? packetsReceived,

    /// Total number of payload bytes sent on this [RTCPeerConnection], i.e.
    /// not including headers or padding.
    ///
    /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
    int? bytesSent,

    /// Total number of bytes received on this [RTCPeerConnection], i.e. not
    /// including headers or padding.
    ///
    /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
    int? bytesReceived,

    /// Set to the current value of the [role][1] of the underlying
    /// [RTCDtlsTransport][2]'s [transport][3].
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-icetransport-role
    /// [2]: https://w3.org/TR/webrtc#rtcdtlstransport-interface
    /// [3]: https://w3.org/TR/webrtc#dom-rtcdtlstransport-icetransport
    IceRole? iceRole,
  }) = RtcStatsType_RtcTransportStats;

  /// Statistics for the remote endpoint's inbound [RTP] stream corresponding
  /// to an outbound stream that is currently sent with [RTCPeerConnection]
  /// object.
  ///
  /// It is measured at the remote endpoint and reported in a RTCP Receiver
  /// Report (RR) or RTCP Extended Report (XR).
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcRemoteInboundRtpStreamStats({
    /// [localId] is used for looking up the local
    /// [RTCOutboundRtpStreamStats][1] object for the same [SSRC].
    ///
    /// [localId]: https://tinyurl.com/r8uhbo9
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcoutboundrtpstreamstats
    String? localId,

    /// Packet jitter measured in seconds for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    double? jitter,

    /// Estimated round trip time for this [SSRC] based on the RTCP
    /// timestamps in the RTCP Receiver Report (RR) and measured in seconds.
    /// Calculated as defined in [Section 6.4.1 of RFC 3550][1].
    /// If no RTCP Receiver Report is received with a DLSR value other than
    /// 0, the round trip time is left undefined.
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    /// [1]: https://tools.ietf.org/html/rfc3550#section-6.4.1
    double? roundTripTime,

    /// Fraction packet loss reported for this [SSRC].
    /// Calculated as defined in [Section 6.4.1 of RFC 3550][1] and
    /// [Appendix A.3][2].
    ///
    /// [1]: https://tools.ietf.org/html/rfc3550#section-6.4.1
    /// [2]: https://tools.ietf.org/html/rfc3550#appendix-A.3
    double? fractionLost,

    /// Total number of RTCP RR blocks received for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? reportsReceived,

    /// Total number of RTCP RR blocks received for this [SSRC] that contain
    /// a valid round trip time. This counter will increment if the
    /// [roundTripTime] is undefined.
    ///
    /// [roundTripTime]: https://tinyurl.com/ssg83hq
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? roundTripTimeMeasurements,
  }) = RtcStatsType_RtcRemoteInboundRtpStreamStats;

  /// Statistics for the remote endpoint's outbound [RTP] stream corresponding
  /// to an inbound stream that is currently received with [RTCPeerConnection]
  /// object.
  ///
  /// It is measured at the remote endpoint and reported in an RTCP Sender
  /// Report (SR).
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcRemoteOutboundRtpStreamStats({
    /// [localId] is used for looking up the local
    /// [RTCInboundRtpStreamStats][1] object for the same [SSRC].
    ///
    /// [localId]: https://tinyurl.com/vu9tb2e
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcinboundrtpstreamstats
    String? localId,

    /// [remoteTimestamp] (as [HIGHRES-TIME]) is the remote timestamp at
    /// which these statistics were sent by the remote endpoint. This
    /// differs from timestamp, which represents the time at which the
    /// statistics were generated or received by the local endpoint. The
    /// [remoteTimestamp], if present, is derived from the NTP timestamp in
    /// an RTCP Sender Report (SR) block, which reflects the remote
    /// endpoint's clock. That clock may not be synchronized with the local
    /// clock.
    ///
    /// [HIGRES-TIME]: https://w3.org/TR/webrtc-stats#bib-highres-time
    /// [remoteTimestamp]: https://tinyurl.com/rzlhs87
    double? remoteTimestamp,

    /// Total number of RTCP SR blocks sent for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? reportsSent,
  }) = RtcStatsType_RtcRemoteOutboundRtpStreamStats;

  /// Unimplemented stats.
  const factory RtcStatsType.unimplemented() = RtcStatsType_Unimplemented;
}

/// Representation of a track event, sent when a new [`MediaStreamTrack`] is
/// added to an [`RtcRtpTransceiver`] as part of a [`PeerConnection`].
class RtcTrackEvent {
  /// [`MediaStreamTrack`] associated with the [RTCRtpReceiver] identified
  /// by the receiver.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  final MediaStreamTrack track;

  /// [`RtcRtpTransceiver`] object associated with the event.
  final RtcRtpTransceiver transceiver;

  RtcTrackEvent({
    required this.track,
    required this.transceiver,
  });
}

/// [RTCRtpTransceiverDirection][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcrtptransceiverdirection
enum RtpTransceiverDirection {
  /// The [`RTCRtpTransceiver`]'s [RTCRtpSender] will offer to send RTP, and
  /// will send RTP if the remote peer accepts. The [`RTCRtpTransceiver`]'s
  /// [RTCRtpReceiver] will offer to receive RTP, and will receive RTP if the
  /// remote peer accepts.
  ///
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  SendRecv,

  /// The [`RTCRtpTransceiver`]'s [RTCRtpSender] will offer to send RTP, and
  /// will send RTP if the remote peer accepts. The [`RTCRtpTransceiver`]'s
  /// [RTCRtpReceiver] will not offer to receive RTP, and will not receive
  /// RTP.
  ///
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  SendOnly,

  /// The [`RTCRtpTransceiver`]'s [RTCRtpSender] will not offer to send RTP,
  /// and will not send RTP. The [`RTCRtpTransceiver`]'s [RTCRtpReceiver] will
  /// offer to receive RTP, and will receive RTP if the remote peer accepts.
  ///
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  RecvOnly,

  /// The [`RTCRtpTransceiver`]'s [RTCRtpSender] will not offer to send RTP,
  /// and will not send RTP. The [`RTCRtpTransceiver`]'s [RTCRtpReceiver] will
  /// not offer to receive RTP, and will not receive RTP.
  ///
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  Inactive,

  /// The [`RTCRtpTransceiver`] will neither send nor receive RTP. It will
  /// generate a zero port in the offer. In answers, its [RTCRtpSender] will
  /// not offer to send RTP, and its [RTCRtpReceiver] will not offer to
  /// receive RTP. This is a terminal state.
  ///
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  Stopped,
}

/// [RTCSdpType] representation.
///
/// [RTCSdpType]: https://w3.org/TR/webrtc#dom-rtcsdptype
enum SdpType {
  /// [RTCSdpType.offer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-offer
  Offer,

  /// [RTCSdpType.pranswer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-pranswer
  PrAnswer,

  /// [RTCSdpType.answer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-answer
  Answer,

  /// [RTCSdpType.rollback][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-rollback
  Rollback,
}

/// [RTCSignalingState] representation.
///
/// [RTCSignalingState]: https://w3.org/TR/webrtc#state-definitions
enum SignalingState {
  /// [RTCSignalingState.stable][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-stable
  Stable,

  /// [RTCSignalingState.have-local-offer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-have-local-offer
  HaveLocalOffer,

  /// [RTCSignalingState.have-local-pranswer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-local-pranswer
  HaveLocalPrAnswer,

  /// [RTCSignalingState.have-remote-offer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-remote-offer
  HaveRemoteOffer,

  /// [RTCSignalingState.have-remote-pranswer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-remote-pranswer
  HaveRemotePrAnswer,

  /// [RTCSignalingState.closed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-closed
  Closed,
}

/// Indicator of the current state of a [`MediaStreamTrack`].
enum TrackEvent {
  /// Ended event of the [`MediaStreamTrack`] interface is fired when playback
  /// or streaming has stopped because the end of the media was reached or
  /// because no further data is available.
  Ended,
}

/// Indicator of the current [MediaStreamTrackState][0] of a
/// [`MediaStreamTrack`].
///
/// [0]: https://w3.org/TR/mediacapture-streams#dom-mediastreamtrackstate
enum TrackState {
  /// [MediaStreamTrackState.live][0] representation.
  ///
  /// [0]: https://tinyurl.com/w3mcs#idl-def-MediaStreamTrackState.live
  Live,

  /// [MediaStreamTrackState.ended][0] representation.
  ///
  /// [0]: https://tinyurl.com/w3mcs#idl-def-MediaStreamTrackState.ended
  Ended,
}

/// Nature and settings of the video [`MediaStreamTrack`] returned by
/// [`Webrtc::get_users_media()`].
class VideoConstraints {
  /// Identifier of the device generating the content of the
  /// [`MediaStreamTrack`].
  ///
  /// First device will be chosen if an empty [`String`] is provided.
  final String? deviceId;

  /// Width in pixels.
  final int width;

  /// Height in pixels.
  final int height;

  /// Exact frame rate (frames per second).
  final int frameRate;

  /// Indicator whether the request video track should be acquired via screen
  /// capturing.
  final bool isDisplay;

  VideoConstraints({
    this.deviceId,
    required this.width,
    required this.height,
    required this.frameRate,
    required this.isDisplay,
  });
}

class FlutterWebrtcNativeImpl implements FlutterWebrtcNative {
  final FlutterWebrtcNativePlatform _platform;
  factory FlutterWebrtcNativeImpl(ExternalLibrary dylib) =>
      FlutterWebrtcNativeImpl.raw(FlutterWebrtcNativePlatform(dylib));

  /// Only valid on web/WASM platforms.
  factory FlutterWebrtcNativeImpl.wasm(FutureOr<WasmModule> module) =>
      FlutterWebrtcNativeImpl(module as ExternalLibrary);
  FlutterWebrtcNativeImpl.raw(this._platform);
  Future<void> enableFakeMedia({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_enable_fake_media(port_),
      parseSuccessData: _wire2api_unit,
      constMeta: kEnableFakeMediaConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kEnableFakeMediaConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "enable_fake_media",
        argNames: [],
      );

  Future<bool> isFakeMedia({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_is_fake_media(port_),
      parseSuccessData: _wire2api_bool,
      constMeta: kIsFakeMediaConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kIsFakeMediaConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "is_fake_media",
        argNames: [],
      );

  Future<List<MediaDeviceInfo>> enumerateDevices({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_enumerate_devices(port_),
      parseSuccessData: _wire2api_list_media_device_info,
      constMeta: kEnumerateDevicesConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kEnumerateDevicesConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "enumerate_devices",
        argNames: [],
      );

  Future<List<AudioSourceInfo>> enumerateSystemAudioSource({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_enumerate_system_audio_source(port_),
      parseSuccessData: _wire2api_list_audio_source_info,
      constMeta: kEnumerateSystemAudioSourceConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kEnumerateSystemAudioSourceConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "enumerate_system_audio_source",
        argNames: [],
      );

  Future<List<MediaDisplayInfo>> enumerateDisplays({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_enumerate_displays(port_),
      parseSuccessData: _wire2api_list_media_display_info,
      constMeta: kEnumerateDisplaysConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kEnumerateDisplaysConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "enumerate_displays",
        argNames: [],
      );

  Stream<PeerConnectionEvent> createPeerConnection(
      {required RtcConfiguration configuration, dynamic hint}) {
    var arg0 = _platform.api2wire_box_autoadd_rtc_configuration(configuration);
    return _platform.executeStream(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_create_peer_connection(port_, arg0),
      parseSuccessData: _wire2api_peer_connection_event,
      constMeta: kCreatePeerConnectionConstMeta,
      argValues: [configuration],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kCreatePeerConnectionConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "create_peer_connection",
        argNames: ["configuration"],
      );

  Future<RtcSessionDescription> createOffer(
      {required int peerId,
      required bool voiceActivityDetection,
      required bool iceRestart,
      required bool useRtpMux,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = voiceActivityDetection;
    var arg2 = iceRestart;
    var arg3 = useRtpMux;
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_create_offer(port_, arg0, arg1, arg2, arg3),
      parseSuccessData: _wire2api_rtc_session_description,
      constMeta: kCreateOfferConstMeta,
      argValues: [peerId, voiceActivityDetection, iceRestart, useRtpMux],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kCreateOfferConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "create_offer",
        argNames: [
          "peerId",
          "voiceActivityDetection",
          "iceRestart",
          "useRtpMux"
        ],
      );

  Future<RtcSessionDescription> createAnswer(
      {required int peerId,
      required bool voiceActivityDetection,
      required bool iceRestart,
      required bool useRtpMux,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = voiceActivityDetection;
    var arg2 = iceRestart;
    var arg3 = useRtpMux;
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_create_answer(port_, arg0, arg1, arg2, arg3),
      parseSuccessData: _wire2api_rtc_session_description,
      constMeta: kCreateAnswerConstMeta,
      argValues: [peerId, voiceActivityDetection, iceRestart, useRtpMux],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kCreateAnswerConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "create_answer",
        argNames: [
          "peerId",
          "voiceActivityDetection",
          "iceRestart",
          "useRtpMux"
        ],
      );

  Future<void> setLocalDescription(
      {required int peerId,
      required SdpType kind,
      required String sdp,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_sdp_type(kind);
    var arg2 = _platform.api2wire_String(sdp);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_local_description(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetLocalDescriptionConstMeta,
      argValues: [peerId, kind, sdp],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetLocalDescriptionConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_local_description",
        argNames: ["peerId", "kind", "sdp"],
      );

  Future<void> setRemoteDescription(
      {required int peerId,
      required SdpType kind,
      required String sdp,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_sdp_type(kind);
    var arg2 = _platform.api2wire_String(sdp);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_remote_description(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetRemoteDescriptionConstMeta,
      argValues: [peerId, kind, sdp],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetRemoteDescriptionConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_remote_description",
        argNames: ["peerId", "kind", "sdp"],
      );

  Future<RtcRtpTransceiver> addTransceiver(
      {required int peerId,
      required MediaType mediaType,
      required RtpTransceiverDirection direction,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_media_type(mediaType);
    var arg2 = api2wire_rtp_transceiver_direction(direction);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_add_transceiver(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_rtc_rtp_transceiver,
      constMeta: kAddTransceiverConstMeta,
      argValues: [peerId, mediaType, direction],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kAddTransceiverConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "add_transceiver",
        argNames: ["peerId", "mediaType", "direction"],
      );

  Future<List<RtcRtpTransceiver>> getTransceivers(
      {required int peerId, dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_get_transceivers(port_, arg0),
      parseSuccessData: _wire2api_list_rtc_rtp_transceiver,
      constMeta: kGetTransceiversConstMeta,
      argValues: [peerId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kGetTransceiversConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "get_transceivers",
        argNames: ["peerId"],
      );

  Future<void> setTransceiverDirection(
      {required int peerId,
      required int transceiverIndex,
      required RtpTransceiverDirection direction,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_u32(transceiverIndex);
    var arg2 = api2wire_rtp_transceiver_direction(direction);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner
          .wire_set_transceiver_direction(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetTransceiverDirectionConstMeta,
      argValues: [peerId, transceiverIndex, direction],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetTransceiverDirectionConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_transceiver_direction",
        argNames: ["peerId", "transceiverIndex", "direction"],
      );

  Future<void> setTransceiverRecv(
      {required int peerId,
      required int transceiverIndex,
      required bool recv,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_u32(transceiverIndex);
    var arg2 = recv;
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_transceiver_recv(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetTransceiverRecvConstMeta,
      argValues: [peerId, transceiverIndex, recv],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetTransceiverRecvConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_transceiver_recv",
        argNames: ["peerId", "transceiverIndex", "recv"],
      );

  Future<void> setTransceiverSend(
      {required int peerId,
      required int transceiverIndex,
      required bool send,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_u32(transceiverIndex);
    var arg2 = send;
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_transceiver_send(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetTransceiverSendConstMeta,
      argValues: [peerId, transceiverIndex, send],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetTransceiverSendConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_transceiver_send",
        argNames: ["peerId", "transceiverIndex", "send"],
      );

  Future<String?> getTransceiverMid(
      {required int peerId, required int transceiverIndex, dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_u32(transceiverIndex);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_get_transceiver_mid(port_, arg0, arg1),
      parseSuccessData: _wire2api_opt_String,
      constMeta: kGetTransceiverMidConstMeta,
      argValues: [peerId, transceiverIndex],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kGetTransceiverMidConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "get_transceiver_mid",
        argNames: ["peerId", "transceiverIndex"],
      );

  Future<RtpTransceiverDirection> getTransceiverDirection(
      {required int peerId, required int transceiverIndex, dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_u32(transceiverIndex);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_get_transceiver_direction(port_, arg0, arg1),
      parseSuccessData: _wire2api_rtp_transceiver_direction,
      constMeta: kGetTransceiverDirectionConstMeta,
      argValues: [peerId, transceiverIndex],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kGetTransceiverDirectionConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "get_transceiver_direction",
        argNames: ["peerId", "transceiverIndex"],
      );

  Future<List<RtcStats>> getPeerStats({required int peerId, dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_get_peer_stats(port_, arg0),
      parseSuccessData: _wire2api_list_rtc_stats,
      constMeta: kGetPeerStatsConstMeta,
      argValues: [peerId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kGetPeerStatsConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "get_peer_stats",
        argNames: ["peerId"],
      );

  Future<void> stopTransceiver(
      {required int peerId, required int transceiverIndex, dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_u32(transceiverIndex);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_stop_transceiver(port_, arg0, arg1),
      parseSuccessData: _wire2api_unit,
      constMeta: kStopTransceiverConstMeta,
      argValues: [peerId, transceiverIndex],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kStopTransceiverConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "stop_transceiver",
        argNames: ["peerId", "transceiverIndex"],
      );

  Future<void> senderReplaceTrack(
      {required int peerId,
      required int transceiverIndex,
      String? trackId,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = api2wire_u32(transceiverIndex);
    var arg2 = _platform.api2wire_opt_String(trackId);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_sender_replace_track(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kSenderReplaceTrackConstMeta,
      argValues: [peerId, transceiverIndex, trackId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSenderReplaceTrackConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "sender_replace_track",
        argNames: ["peerId", "transceiverIndex", "trackId"],
      );

  Future<void> addIceCandidate(
      {required int peerId,
      required String candidate,
      required String sdpMid,
      required int sdpMlineIndex,
      dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    var arg1 = _platform.api2wire_String(candidate);
    var arg2 = _platform.api2wire_String(sdpMid);
    var arg3 = api2wire_i32(sdpMlineIndex);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_add_ice_candidate(port_, arg0, arg1, arg2, arg3),
      parseSuccessData: _wire2api_unit,
      constMeta: kAddIceCandidateConstMeta,
      argValues: [peerId, candidate, sdpMid, sdpMlineIndex],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kAddIceCandidateConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "add_ice_candidate",
        argNames: ["peerId", "candidate", "sdpMid", "sdpMlineIndex"],
      );

  Future<void> restartIce({required int peerId, dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_restart_ice(port_, arg0),
      parseSuccessData: _wire2api_unit,
      constMeta: kRestartIceConstMeta,
      argValues: [peerId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kRestartIceConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "restart_ice",
        argNames: ["peerId"],
      );

  Future<void> disposePeerConnection({required int peerId, dynamic hint}) {
    var arg0 = _platform.api2wire_u64(peerId);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_dispose_peer_connection(port_, arg0),
      parseSuccessData: _wire2api_unit,
      constMeta: kDisposePeerConnectionConstMeta,
      argValues: [peerId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kDisposePeerConnectionConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "dispose_peer_connection",
        argNames: ["peerId"],
      );

  Future<GetMediaResult> getMedia(
      {required MediaStreamConstraints constraints, dynamic hint}) {
    var arg0 =
        _platform.api2wire_box_autoadd_media_stream_constraints(constraints);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_get_media(port_, arg0),
      parseSuccessData: _wire2api_get_media_result,
      constMeta: kGetMediaConstMeta,
      argValues: [constraints],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kGetMediaConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "get_media",
        argNames: ["constraints"],
      );

  Future<void> setAudioPlayoutDevice({required String deviceId, dynamic hint}) {
    var arg0 = _platform.api2wire_String(deviceId);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_audio_playout_device(port_, arg0),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetAudioPlayoutDeviceConstMeta,
      argValues: [deviceId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetAudioPlayoutDeviceConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_audio_playout_device",
        argNames: ["deviceId"],
      );

  Future<bool> microphoneVolumeIsAvailable({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_microphone_volume_is_available(port_),
      parseSuccessData: _wire2api_bool,
      constMeta: kMicrophoneVolumeIsAvailableConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kMicrophoneVolumeIsAvailableConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "microphone_volume_is_available",
        argNames: [],
      );

  Future<void> setMicrophoneVolume({required int level, dynamic hint}) {
    var arg0 = api2wire_u8(level);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_microphone_volume(port_, arg0),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetMicrophoneVolumeConstMeta,
      argValues: [level],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetMicrophoneVolumeConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_microphone_volume",
        argNames: ["level"],
      );

  Future<int> microphoneVolume({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_microphone_volume(port_),
      parseSuccessData: _wire2api_u32,
      constMeta: kMicrophoneVolumeConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kMicrophoneVolumeConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "microphone_volume",
        argNames: [],
      );

  Future<void> disposeTrack(
      {required String trackId, required MediaType kind, dynamic hint}) {
    var arg0 = _platform.api2wire_String(trackId);
    var arg1 = api2wire_media_type(kind);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_dispose_track(port_, arg0, arg1),
      parseSuccessData: _wire2api_unit,
      constMeta: kDisposeTrackConstMeta,
      argValues: [trackId, kind],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kDisposeTrackConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "dispose_track",
        argNames: ["trackId", "kind"],
      );

  Future<TrackState> trackState(
      {required String trackId, required MediaType kind, dynamic hint}) {
    var arg0 = _platform.api2wire_String(trackId);
    var arg1 = api2wire_media_type(kind);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_track_state(port_, arg0, arg1),
      parseSuccessData: _wire2api_track_state,
      constMeta: kTrackStateConstMeta,
      argValues: [trackId, kind],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kTrackStateConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "track_state",
        argNames: ["trackId", "kind"],
      );

  Future<void> setTrackEnabled(
      {required String trackId,
      required MediaType kind,
      required bool enabled,
      dynamic hint}) {
    var arg0 = _platform.api2wire_String(trackId);
    var arg1 = api2wire_media_type(kind);
    var arg2 = enabled;
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_track_enabled(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetTrackEnabledConstMeta,
      argValues: [trackId, kind, enabled],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetTrackEnabledConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_track_enabled",
        argNames: ["trackId", "kind", "enabled"],
      );

  Future<MediaStreamTrack> cloneTrack(
      {required String trackId, required MediaType kind, dynamic hint}) {
    var arg0 = _platform.api2wire_String(trackId);
    var arg1 = api2wire_media_type(kind);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_clone_track(port_, arg0, arg1),
      parseSuccessData: _wire2api_media_stream_track,
      constMeta: kCloneTrackConstMeta,
      argValues: [trackId, kind],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kCloneTrackConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "clone_track",
        argNames: ["trackId", "kind"],
      );

  Future<void> setSystemAudioVolume({required double level, dynamic hint}) {
    var arg0 = api2wire_f32(level);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_system_audio_volume(port_, arg0),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetSystemAudioVolumeConstMeta,
      argValues: [level],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetSystemAudioVolumeConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_system_audio_volume",
        argNames: ["level"],
      );

  Future<double> systemAudioVolume({dynamic hint}) {
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_system_audio_volume(port_),
      parseSuccessData: _wire2api_f32,
      constMeta: kSystemAudioVolumeConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSystemAudioVolumeConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "system_audio_volume",
        argNames: [],
      );

  Stream<TrackEvent> registerTrackObserver(
      {required String trackId, required MediaType kind, dynamic hint}) {
    var arg0 = _platform.api2wire_String(trackId);
    var arg1 = api2wire_media_type(kind);
    return _platform.executeStream(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_register_track_observer(port_, arg0, arg1),
      parseSuccessData: _wire2api_track_event,
      constMeta: kRegisterTrackObserverConstMeta,
      argValues: [trackId, kind],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kRegisterTrackObserverConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "register_track_observer",
        argNames: ["trackId", "kind"],
      );

  Stream<void> setOnDeviceChanged({dynamic hint}) {
    return _platform.executeStream(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_set_on_device_changed(port_),
      parseSuccessData: _wire2api_unit,
      constMeta: kSetOnDeviceChangedConstMeta,
      argValues: [],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetOnDeviceChangedConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_on_device_changed",
        argNames: [],
      );

  Stream<double> setOnAudioLevelChanged(
      {required String trackId, dynamic hint}) {
    var arg0 = _platform.api2wire_String(trackId);
    return _platform.executeStream(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_set_on_audio_level_changed(port_, arg0),
      parseSuccessData: _wire2api_f32,
      constMeta: kSetOnAudioLevelChangedConstMeta,
      argValues: [trackId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kSetOnAudioLevelChangedConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "set_on_audio_level_changed",
        argNames: ["trackId"],
      );

  Future<void> createVideoSink(
      {required int sinkId,
      required String trackId,
      required int callbackPtr,
      dynamic hint}) {
    var arg0 = _platform.api2wire_i64(sinkId);
    var arg1 = _platform.api2wire_String(trackId);
    var arg2 = _platform.api2wire_u64(callbackPtr);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) =>
          _platform.inner.wire_create_video_sink(port_, arg0, arg1, arg2),
      parseSuccessData: _wire2api_unit,
      constMeta: kCreateVideoSinkConstMeta,
      argValues: [sinkId, trackId, callbackPtr],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kCreateVideoSinkConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "create_video_sink",
        argNames: ["sinkId", "trackId", "callbackPtr"],
      );

  Future<void> disposeVideoSink({required int sinkId, dynamic hint}) {
    var arg0 = _platform.api2wire_i64(sinkId);
    return _platform.executeNormal(FlutterRustBridgeTask(
      callFfi: (port_) => _platform.inner.wire_dispose_video_sink(port_, arg0),
      parseSuccessData: _wire2api_unit,
      constMeta: kDisposeVideoSinkConstMeta,
      argValues: [sinkId],
      hint: hint,
    ));
  }

  FlutterRustBridgeTaskConstMeta get kDisposeVideoSinkConstMeta =>
      const FlutterRustBridgeTaskConstMeta(
        debugName: "dispose_video_sink",
        argNames: ["sinkId"],
      );

  void dispose() {
    _platform.dispose();
  }
// Section: wire2api

  String _wire2api_String(dynamic raw) {
    return raw as String;
  }

  AudioSourceInfo _wire2api_audio_source_info(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return AudioSourceInfo(
      id: _wire2api_i64(arr[0]),
      title: _wire2api_String(arr[1]),
    );
  }

  bool _wire2api_bool(dynamic raw) {
    return raw as bool;
  }

  bool _wire2api_box_autoadd_bool(dynamic raw) {
    return raw as bool;
  }

  double _wire2api_box_autoadd_f64(dynamic raw) {
    return raw as double;
  }

  GetMediaError _wire2api_box_autoadd_get_media_error(dynamic raw) {
    return _wire2api_get_media_error(raw);
  }

  int _wire2api_box_autoadd_i32(dynamic raw) {
    return raw as int;
  }

  IceCandidateStats _wire2api_box_autoadd_ice_candidate_stats(dynamic raw) {
    return _wire2api_ice_candidate_stats(raw);
  }

  IceRole _wire2api_box_autoadd_ice_role(dynamic raw) {
    return _wire2api_ice_role(raw);
  }

  Protocol _wire2api_box_autoadd_protocol(dynamic raw) {
    return _wire2api_protocol(raw);
  }

  RtcIceCandidateStats _wire2api_box_autoadd_rtc_ice_candidate_stats(
      dynamic raw) {
    return _wire2api_rtc_ice_candidate_stats(raw);
  }

  RtcInboundRtpStreamMediaType
      _wire2api_box_autoadd_rtc_inbound_rtp_stream_media_type(dynamic raw) {
    return _wire2api_rtc_inbound_rtp_stream_media_type(raw);
  }

  RtcMediaSourceStatsMediaType
      _wire2api_box_autoadd_rtc_media_source_stats_media_type(dynamic raw) {
    return _wire2api_rtc_media_source_stats_media_type(raw);
  }

  RtcOutboundRtpStreamStatsMediaType
      _wire2api_box_autoadd_rtc_outbound_rtp_stream_stats_media_type(
          dynamic raw) {
    return _wire2api_rtc_outbound_rtp_stream_stats_media_type(raw);
  }

  RtcTrackEvent _wire2api_box_autoadd_rtc_track_event(dynamic raw) {
    return _wire2api_rtc_track_event(raw);
  }

  int _wire2api_box_autoadd_u32(dynamic raw) {
    return raw as int;
  }

  int _wire2api_box_autoadd_u64(dynamic raw) {
    return _wire2api_u64(raw);
  }

  CandidateType _wire2api_candidate_type(dynamic raw) {
    return CandidateType.values[raw];
  }

  double _wire2api_f32(dynamic raw) {
    return raw as double;
  }

  double _wire2api_f64(dynamic raw) {
    return raw as double;
  }

  GetMediaError _wire2api_get_media_error(dynamic raw) {
    switch (raw[0]) {
      case 0:
        return GetMediaError_Audio(
          _wire2api_String(raw[1]),
        );
      case 1:
        return GetMediaError_Video(
          _wire2api_String(raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  GetMediaResult _wire2api_get_media_result(dynamic raw) {
    switch (raw[0]) {
      case 0:
        return GetMediaResult_Ok(
          _wire2api_list_media_stream_track(raw[1]),
        );
      case 1:
        return GetMediaResult_Err(
          _wire2api_box_autoadd_get_media_error(raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  int _wire2api_i32(dynamic raw) {
    return raw as int;
  }

  int _wire2api_i64(dynamic raw) {
    return castInt(raw);
  }

  IceCandidateStats _wire2api_ice_candidate_stats(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 8)
      throw Exception('unexpected arr length: expect 8 but see ${arr.length}');
    return IceCandidateStats(
      transportId: _wire2api_opt_String(arr[0]),
      address: _wire2api_opt_String(arr[1]),
      port: _wire2api_opt_box_autoadd_i32(arr[2]),
      protocol: _wire2api_protocol(arr[3]),
      candidateType: _wire2api_candidate_type(arr[4]),
      priority: _wire2api_opt_box_autoadd_i32(arr[5]),
      url: _wire2api_opt_String(arr[6]),
      relayProtocol: _wire2api_opt_box_autoadd_protocol(arr[7]),
    );
  }

  IceConnectionState _wire2api_ice_connection_state(dynamic raw) {
    return IceConnectionState.values[raw];
  }

  IceGatheringState _wire2api_ice_gathering_state(dynamic raw) {
    return IceGatheringState.values[raw];
  }

  IceRole _wire2api_ice_role(dynamic raw) {
    return IceRole.values[raw];
  }

  List<AudioSourceInfo> _wire2api_list_audio_source_info(dynamic raw) {
    return (raw as List<dynamic>).map(_wire2api_audio_source_info).toList();
  }

  List<MediaDeviceInfo> _wire2api_list_media_device_info(dynamic raw) {
    return (raw as List<dynamic>).map(_wire2api_media_device_info).toList();
  }

  List<MediaDisplayInfo> _wire2api_list_media_display_info(dynamic raw) {
    return (raw as List<dynamic>).map(_wire2api_media_display_info).toList();
  }

  List<MediaStreamTrack> _wire2api_list_media_stream_track(dynamic raw) {
    return (raw as List<dynamic>).map(_wire2api_media_stream_track).toList();
  }

  List<RtcRtpTransceiver> _wire2api_list_rtc_rtp_transceiver(dynamic raw) {
    return (raw as List<dynamic>).map(_wire2api_rtc_rtp_transceiver).toList();
  }

  List<RtcStats> _wire2api_list_rtc_stats(dynamic raw) {
    return (raw as List<dynamic>).map(_wire2api_rtc_stats).toList();
  }

  MediaDeviceInfo _wire2api_media_device_info(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return MediaDeviceInfo(
      deviceId: _wire2api_String(arr[0]),
      kind: _wire2api_media_device_kind(arr[1]),
      label: _wire2api_String(arr[2]),
    );
  }

  MediaDeviceKind _wire2api_media_device_kind(dynamic raw) {
    return MediaDeviceKind.values[raw];
  }

  MediaDisplayInfo _wire2api_media_display_info(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return MediaDisplayInfo(
      deviceId: _wire2api_String(arr[0]),
      title: _wire2api_opt_String(arr[1]),
    );
  }

  MediaStreamTrack _wire2api_media_stream_track(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 4)
      throw Exception('unexpected arr length: expect 4 but see ${arr.length}');
    return MediaStreamTrack(
      id: _wire2api_String(arr[0]),
      deviceId: _wire2api_String(arr[1]),
      kind: _wire2api_media_type(arr[2]),
      enabled: _wire2api_bool(arr[3]),
    );
  }

  MediaType _wire2api_media_type(dynamic raw) {
    return MediaType.values[raw];
  }

  String? _wire2api_opt_String(dynamic raw) {
    return raw == null ? null : _wire2api_String(raw);
  }

  bool? _wire2api_opt_box_autoadd_bool(dynamic raw) {
    return raw == null ? null : _wire2api_box_autoadd_bool(raw);
  }

  double? _wire2api_opt_box_autoadd_f64(dynamic raw) {
    return raw == null ? null : _wire2api_box_autoadd_f64(raw);
  }

  int? _wire2api_opt_box_autoadd_i32(dynamic raw) {
    return raw == null ? null : _wire2api_box_autoadd_i32(raw);
  }

  IceRole? _wire2api_opt_box_autoadd_ice_role(dynamic raw) {
    return raw == null ? null : _wire2api_box_autoadd_ice_role(raw);
  }

  Protocol? _wire2api_opt_box_autoadd_protocol(dynamic raw) {
    return raw == null ? null : _wire2api_box_autoadd_protocol(raw);
  }

  RtcInboundRtpStreamMediaType?
      _wire2api_opt_box_autoadd_rtc_inbound_rtp_stream_media_type(dynamic raw) {
    return raw == null
        ? null
        : _wire2api_box_autoadd_rtc_inbound_rtp_stream_media_type(raw);
  }

  int? _wire2api_opt_box_autoadd_u32(dynamic raw) {
    return raw == null ? null : _wire2api_box_autoadd_u32(raw);
  }

  int? _wire2api_opt_box_autoadd_u64(dynamic raw) {
    return raw == null ? null : _wire2api_box_autoadd_u64(raw);
  }

  PeerConnectionEvent _wire2api_peer_connection_event(dynamic raw) {
    switch (raw[0]) {
      case 0:
        return PeerConnectionEvent_PeerCreated(
          id: _wire2api_u64(raw[1]),
        );
      case 1:
        return PeerConnectionEvent_IceCandidate(
          sdpMid: _wire2api_String(raw[1]),
          sdpMlineIndex: _wire2api_i32(raw[2]),
          candidate: _wire2api_String(raw[3]),
        );
      case 2:
        return PeerConnectionEvent_IceGatheringStateChange(
          _wire2api_ice_gathering_state(raw[1]),
        );
      case 3:
        return PeerConnectionEvent_IceCandidateError(
          address: _wire2api_String(raw[1]),
          port: _wire2api_i32(raw[2]),
          url: _wire2api_String(raw[3]),
          errorCode: _wire2api_i32(raw[4]),
          errorText: _wire2api_String(raw[5]),
        );
      case 4:
        return PeerConnectionEvent_NegotiationNeeded();
      case 5:
        return PeerConnectionEvent_SignallingChange(
          _wire2api_signaling_state(raw[1]),
        );
      case 6:
        return PeerConnectionEvent_IceConnectionStateChange(
          _wire2api_ice_connection_state(raw[1]),
        );
      case 7:
        return PeerConnectionEvent_ConnectionStateChange(
          _wire2api_peer_connection_state(raw[1]),
        );
      case 8:
        return PeerConnectionEvent_Track(
          _wire2api_box_autoadd_rtc_track_event(raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  PeerConnectionState _wire2api_peer_connection_state(dynamic raw) {
    return PeerConnectionState.values[raw];
  }

  Protocol _wire2api_protocol(dynamic raw) {
    return Protocol.values[raw];
  }

  RtcIceCandidateStats _wire2api_rtc_ice_candidate_stats(dynamic raw) {
    switch (raw[0]) {
      case 0:
        return RtcIceCandidateStats_Local(
          _wire2api_box_autoadd_ice_candidate_stats(raw[1]),
        );
      case 1:
        return RtcIceCandidateStats_Remote(
          _wire2api_box_autoadd_ice_candidate_stats(raw[1]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  RtcInboundRtpStreamMediaType _wire2api_rtc_inbound_rtp_stream_media_type(
      dynamic raw) {
    switch (raw[0]) {
      case 0:
        return RtcInboundRtpStreamMediaType_Audio(
          voiceActivityFlag: _wire2api_opt_box_autoadd_bool(raw[1]),
          totalSamplesReceived: _wire2api_opt_box_autoadd_u64(raw[2]),
          concealedSamples: _wire2api_opt_box_autoadd_u64(raw[3]),
          silentConcealedSamples: _wire2api_opt_box_autoadd_u64(raw[4]),
          audioLevel: _wire2api_opt_box_autoadd_f64(raw[5]),
          totalAudioEnergy: _wire2api_opt_box_autoadd_f64(raw[6]),
          totalSamplesDuration: _wire2api_opt_box_autoadd_f64(raw[7]),
        );
      case 1:
        return RtcInboundRtpStreamMediaType_Video(
          framesDecoded: _wire2api_opt_box_autoadd_u32(raw[1]),
          keyFramesDecoded: _wire2api_opt_box_autoadd_u32(raw[2]),
          frameWidth: _wire2api_opt_box_autoadd_u32(raw[3]),
          frameHeight: _wire2api_opt_box_autoadd_u32(raw[4]),
          totalInterFrameDelay: _wire2api_opt_box_autoadd_f64(raw[5]),
          framesPerSecond: _wire2api_opt_box_autoadd_f64(raw[6]),
          firCount: _wire2api_opt_box_autoadd_u32(raw[7]),
          pliCount: _wire2api_opt_box_autoadd_u32(raw[8]),
          sliCount: _wire2api_opt_box_autoadd_u32(raw[9]),
          concealmentEvents: _wire2api_opt_box_autoadd_u64(raw[10]),
          framesReceived: _wire2api_opt_box_autoadd_i32(raw[11]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  RtcMediaSourceStatsMediaType _wire2api_rtc_media_source_stats_media_type(
      dynamic raw) {
    switch (raw[0]) {
      case 0:
        return RtcMediaSourceStatsMediaType_RtcVideoSourceStats(
          width: _wire2api_opt_box_autoadd_u32(raw[1]),
          height: _wire2api_opt_box_autoadd_u32(raw[2]),
          frames: _wire2api_opt_box_autoadd_u32(raw[3]),
          framesPerSecond: _wire2api_opt_box_autoadd_f64(raw[4]),
        );
      case 1:
        return RtcMediaSourceStatsMediaType_RtcAudioSourceStats(
          audioLevel: _wire2api_opt_box_autoadd_f64(raw[1]),
          totalAudioEnergy: _wire2api_opt_box_autoadd_f64(raw[2]),
          totalSamplesDuration: _wire2api_opt_box_autoadd_f64(raw[3]),
          echoReturnLoss: _wire2api_opt_box_autoadd_f64(raw[4]),
          echoReturnLossEnhancement: _wire2api_opt_box_autoadd_f64(raw[5]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  RtcOutboundRtpStreamStatsMediaType
      _wire2api_rtc_outbound_rtp_stream_stats_media_type(dynamic raw) {
    switch (raw[0]) {
      case 0:
        return RtcOutboundRtpStreamStatsMediaType_Audio(
          totalSamplesSent: _wire2api_opt_box_autoadd_u64(raw[1]),
          voiceActivityFlag: _wire2api_opt_box_autoadd_bool(raw[2]),
        );
      case 1:
        return RtcOutboundRtpStreamStatsMediaType_Video(
          frameWidth: _wire2api_opt_box_autoadd_u32(raw[1]),
          frameHeight: _wire2api_opt_box_autoadd_u32(raw[2]),
          framesPerSecond: _wire2api_opt_box_autoadd_f64(raw[3]),
        );
      default:
        throw Exception("unreachable");
    }
  }

  RtcRtpTransceiver _wire2api_rtc_rtp_transceiver(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 4)
      throw Exception('unexpected arr length: expect 4 but see ${arr.length}');
    return RtcRtpTransceiver(
      peerId: _wire2api_u64(arr[0]),
      index: _wire2api_u64(arr[1]),
      mid: _wire2api_opt_String(arr[2]),
      direction: _wire2api_rtp_transceiver_direction(arr[3]),
    );
  }

  RtcSessionDescription _wire2api_rtc_session_description(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return RtcSessionDescription(
      sdp: _wire2api_String(arr[0]),
      kind: _wire2api_sdp_type(arr[1]),
    );
  }

  RtcStats _wire2api_rtc_stats(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 3)
      throw Exception('unexpected arr length: expect 3 but see ${arr.length}');
    return RtcStats(
      id: _wire2api_String(arr[0]),
      timestampUs: _wire2api_i64(arr[1]),
      kind: _wire2api_rtc_stats_type(arr[2]),
    );
  }

  RtcStatsIceCandidatePairState _wire2api_rtc_stats_ice_candidate_pair_state(
      dynamic raw) {
    return RtcStatsIceCandidatePairState.values[raw];
  }

  RtcStatsType _wire2api_rtc_stats_type(dynamic raw) {
    switch (raw[0]) {
      case 0:
        return RtcStatsType_RtcMediaSourceStats(
          trackIdentifier: _wire2api_opt_String(raw[1]),
          kind: _wire2api_box_autoadd_rtc_media_source_stats_media_type(raw[2]),
        );
      case 1:
        return RtcStatsType_RtcIceCandidateStats(
          _wire2api_box_autoadd_rtc_ice_candidate_stats(raw[1]),
        );
      case 2:
        return RtcStatsType_RtcOutboundRtpStreamStats(
          trackId: _wire2api_opt_String(raw[1]),
          mediaType:
              _wire2api_box_autoadd_rtc_outbound_rtp_stream_stats_media_type(
                  raw[2]),
          bytesSent: _wire2api_opt_box_autoadd_u64(raw[3]),
          packetsSent: _wire2api_opt_box_autoadd_u32(raw[4]),
          mediaSourceId: _wire2api_opt_String(raw[5]),
        );
      case 3:
        return RtcStatsType_RtcInboundRtpStreamStats(
          remoteId: _wire2api_opt_String(raw[1]),
          bytesReceived: _wire2api_opt_box_autoadd_u64(raw[2]),
          packetsReceived: _wire2api_opt_box_autoadd_u32(raw[3]),
          packetsLost: _wire2api_opt_box_autoadd_u64(raw[4]),
          jitter: _wire2api_opt_box_autoadd_f64(raw[5]),
          totalDecodeTime: _wire2api_opt_box_autoadd_f64(raw[6]),
          jitterBufferEmittedCount: _wire2api_opt_box_autoadd_u64(raw[7]),
          mediaType:
              _wire2api_opt_box_autoadd_rtc_inbound_rtp_stream_media_type(
                  raw[8]),
        );
      case 4:
        return RtcStatsType_RtcIceCandidatePairStats(
          state: _wire2api_rtc_stats_ice_candidate_pair_state(raw[1]),
          nominated: _wire2api_opt_box_autoadd_bool(raw[2]),
          bytesSent: _wire2api_opt_box_autoadd_u64(raw[3]),
          bytesReceived: _wire2api_opt_box_autoadd_u64(raw[4]),
          totalRoundTripTime: _wire2api_opt_box_autoadd_f64(raw[5]),
          currentRoundTripTime: _wire2api_opt_box_autoadd_f64(raw[6]),
          availableOutgoingBitrate: _wire2api_opt_box_autoadd_f64(raw[7]),
        );
      case 5:
        return RtcStatsType_RtcTransportStats(
          packetsSent: _wire2api_opt_box_autoadd_u64(raw[1]),
          packetsReceived: _wire2api_opt_box_autoadd_u64(raw[2]),
          bytesSent: _wire2api_opt_box_autoadd_u64(raw[3]),
          bytesReceived: _wire2api_opt_box_autoadd_u64(raw[4]),
          iceRole: _wire2api_opt_box_autoadd_ice_role(raw[5]),
        );
      case 6:
        return RtcStatsType_RtcRemoteInboundRtpStreamStats(
          localId: _wire2api_opt_String(raw[1]),
          jitter: _wire2api_opt_box_autoadd_f64(raw[2]),
          roundTripTime: _wire2api_opt_box_autoadd_f64(raw[3]),
          fractionLost: _wire2api_opt_box_autoadd_f64(raw[4]),
          reportsReceived: _wire2api_opt_box_autoadd_u64(raw[5]),
          roundTripTimeMeasurements: _wire2api_opt_box_autoadd_i32(raw[6]),
        );
      case 7:
        return RtcStatsType_RtcRemoteOutboundRtpStreamStats(
          localId: _wire2api_opt_String(raw[1]),
          remoteTimestamp: _wire2api_opt_box_autoadd_f64(raw[2]),
          reportsSent: _wire2api_opt_box_autoadd_u64(raw[3]),
        );
      case 8:
        return RtcStatsType_Unimplemented();
      default:
        throw Exception("unreachable");
    }
  }

  RtcTrackEvent _wire2api_rtc_track_event(dynamic raw) {
    final arr = raw as List<dynamic>;
    if (arr.length != 2)
      throw Exception('unexpected arr length: expect 2 but see ${arr.length}');
    return RtcTrackEvent(
      track: _wire2api_media_stream_track(arr[0]),
      transceiver: _wire2api_rtc_rtp_transceiver(arr[1]),
    );
  }

  RtpTransceiverDirection _wire2api_rtp_transceiver_direction(dynamic raw) {
    return RtpTransceiverDirection.values[raw];
  }

  SdpType _wire2api_sdp_type(dynamic raw) {
    return SdpType.values[raw];
  }

  SignalingState _wire2api_signaling_state(dynamic raw) {
    return SignalingState.values[raw];
  }

  TrackEvent _wire2api_track_event(dynamic raw) {
    return TrackEvent.values[raw];
  }

  TrackState _wire2api_track_state(dynamic raw) {
    return TrackState.values[raw];
  }

  int _wire2api_u32(dynamic raw) {
    return raw as int;
  }

  int _wire2api_u64(dynamic raw) {
    return castInt(raw);
  }

  int _wire2api_u8(dynamic raw) {
    return raw as int;
  }

  Uint8List _wire2api_uint_8_list(dynamic raw) {
    return raw as Uint8List;
  }

  void _wire2api_unit(dynamic raw) {
    return;
  }
}

// Section: api2wire

@protected
bool api2wire_bool(bool raw) {
  return raw;
}

@protected
int api2wire_bundle_policy(BundlePolicy raw) {
  return api2wire_i32(raw.index);
}

@protected
double api2wire_f32(double raw) {
  return raw;
}

@protected
int api2wire_i32(int raw) {
  return raw;
}

@protected
int api2wire_ice_transports_type(IceTransportsType raw) {
  return api2wire_i32(raw.index);
}

@protected
int api2wire_media_type(MediaType raw) {
  return api2wire_i32(raw.index);
}

@protected
int api2wire_rtp_transceiver_direction(RtpTransceiverDirection raw) {
  return api2wire_i32(raw.index);
}

@protected
int api2wire_sdp_type(SdpType raw) {
  return api2wire_i32(raw.index);
}

@protected
int api2wire_u32(int raw) {
  return raw;
}

@protected
int api2wire_u8(int raw) {
  return raw;
}

// Section: finalizer

class FlutterWebrtcNativePlatform
    extends FlutterRustBridgeBase<FlutterWebrtcNativeWire> {
  FlutterWebrtcNativePlatform(ffi.DynamicLibrary dylib)
      : super(FlutterWebrtcNativeWire(dylib));

// Section: api2wire

  @protected
  ffi.Pointer<wire_uint_8_list> api2wire_String(String raw) {
    return api2wire_uint_8_list(utf8.encoder.convert(raw));
  }

  @protected
  ffi.Pointer<wire_StringList> api2wire_StringList(List<String> raw) {
    final ans = inner.new_StringList_0(raw.length);
    for (var i = 0; i < raw.length; i++) {
      ans.ref.ptr[i] = api2wire_String(raw[i]);
    }
    return ans;
  }

  @protected
  ffi.Pointer<wire_AudioConstraints> api2wire_box_autoadd_audio_constraints(
      AudioConstraints raw) {
    final ptr = inner.new_box_autoadd_audio_constraints_0();
    _api_fill_to_wire_audio_constraints(raw, ptr.ref);
    return ptr;
  }

  @protected
  ffi.Pointer<ffi.Int64> api2wire_box_autoadd_i64(int raw) {
    return inner.new_box_autoadd_i64_0(api2wire_i64(raw));
  }

  @protected
  ffi.Pointer<wire_MediaStreamConstraints>
      api2wire_box_autoadd_media_stream_constraints(
          MediaStreamConstraints raw) {
    final ptr = inner.new_box_autoadd_media_stream_constraints_0();
    _api_fill_to_wire_media_stream_constraints(raw, ptr.ref);
    return ptr;
  }

  @protected
  ffi.Pointer<wire_RtcConfiguration> api2wire_box_autoadd_rtc_configuration(
      RtcConfiguration raw) {
    final ptr = inner.new_box_autoadd_rtc_configuration_0();
    _api_fill_to_wire_rtc_configuration(raw, ptr.ref);
    return ptr;
  }

  @protected
  ffi.Pointer<wire_VideoConstraints> api2wire_box_autoadd_video_constraints(
      VideoConstraints raw) {
    final ptr = inner.new_box_autoadd_video_constraints_0();
    _api_fill_to_wire_video_constraints(raw, ptr.ref);
    return ptr;
  }

  @protected
  int api2wire_i64(int raw) {
    return raw;
  }

  @protected
  ffi.Pointer<wire_list_rtc_ice_server> api2wire_list_rtc_ice_server(
      List<RtcIceServer> raw) {
    final ans = inner.new_list_rtc_ice_server_0(raw.length);
    for (var i = 0; i < raw.length; ++i) {
      _api_fill_to_wire_rtc_ice_server(raw[i], ans.ref.ptr[i]);
    }
    return ans;
  }

  @protected
  ffi.Pointer<wire_uint_8_list> api2wire_opt_String(String? raw) {
    return raw == null ? ffi.nullptr : api2wire_String(raw);
  }

  @protected
  ffi.Pointer<wire_AudioConstraints> api2wire_opt_box_autoadd_audio_constraints(
      AudioConstraints? raw) {
    return raw == null
        ? ffi.nullptr
        : api2wire_box_autoadd_audio_constraints(raw);
  }

  @protected
  ffi.Pointer<ffi.Int64> api2wire_opt_box_autoadd_i64(int? raw) {
    return raw == null ? ffi.nullptr : api2wire_box_autoadd_i64(raw);
  }

  @protected
  ffi.Pointer<wire_VideoConstraints> api2wire_opt_box_autoadd_video_constraints(
      VideoConstraints? raw) {
    return raw == null
        ? ffi.nullptr
        : api2wire_box_autoadd_video_constraints(raw);
  }

  @protected
  int api2wire_u64(int raw) {
    return raw;
  }

  @protected
  ffi.Pointer<wire_uint_8_list> api2wire_uint_8_list(Uint8List raw) {
    final ans = inner.new_uint_8_list_0(raw.length);
    ans.ref.ptr.asTypedList(raw.length).setAll(0, raw);
    return ans;
  }

// Section: finalizer

// Section: api_fill_to_wire

  void _api_fill_to_wire_audio_constraints(
      AudioConstraints apiObj, wire_AudioConstraints wireObj) {
    wireObj.device_id = api2wire_opt_String(apiObj.deviceId);
    wireObj.system_id = api2wire_opt_box_autoadd_i64(apiObj.systemId);
  }

  void _api_fill_to_wire_box_autoadd_audio_constraints(
      AudioConstraints apiObj, ffi.Pointer<wire_AudioConstraints> wireObj) {
    _api_fill_to_wire_audio_constraints(apiObj, wireObj.ref);
  }

  void _api_fill_to_wire_box_autoadd_media_stream_constraints(
      MediaStreamConstraints apiObj,
      ffi.Pointer<wire_MediaStreamConstraints> wireObj) {
    _api_fill_to_wire_media_stream_constraints(apiObj, wireObj.ref);
  }

  void _api_fill_to_wire_box_autoadd_rtc_configuration(
      RtcConfiguration apiObj, ffi.Pointer<wire_RtcConfiguration> wireObj) {
    _api_fill_to_wire_rtc_configuration(apiObj, wireObj.ref);
  }

  void _api_fill_to_wire_box_autoadd_video_constraints(
      VideoConstraints apiObj, ffi.Pointer<wire_VideoConstraints> wireObj) {
    _api_fill_to_wire_video_constraints(apiObj, wireObj.ref);
  }

  void _api_fill_to_wire_media_stream_constraints(
      MediaStreamConstraints apiObj, wire_MediaStreamConstraints wireObj) {
    wireObj.audio = api2wire_opt_box_autoadd_audio_constraints(apiObj.audio);
    wireObj.video = api2wire_opt_box_autoadd_video_constraints(apiObj.video);
  }

  void _api_fill_to_wire_opt_box_autoadd_audio_constraints(
      AudioConstraints? apiObj, ffi.Pointer<wire_AudioConstraints> wireObj) {
    if (apiObj != null)
      _api_fill_to_wire_box_autoadd_audio_constraints(apiObj, wireObj);
  }

  void _api_fill_to_wire_opt_box_autoadd_video_constraints(
      VideoConstraints? apiObj, ffi.Pointer<wire_VideoConstraints> wireObj) {
    if (apiObj != null)
      _api_fill_to_wire_box_autoadd_video_constraints(apiObj, wireObj);
  }

  void _api_fill_to_wire_rtc_configuration(
      RtcConfiguration apiObj, wire_RtcConfiguration wireObj) {
    wireObj.ice_transport_policy =
        api2wire_ice_transports_type(apiObj.iceTransportPolicy);
    wireObj.bundle_policy = api2wire_bundle_policy(apiObj.bundlePolicy);
    wireObj.ice_servers = api2wire_list_rtc_ice_server(apiObj.iceServers);
  }

  void _api_fill_to_wire_rtc_ice_server(
      RtcIceServer apiObj, wire_RtcIceServer wireObj) {
    wireObj.urls = api2wire_StringList(apiObj.urls);
    wireObj.username = api2wire_String(apiObj.username);
    wireObj.credential = api2wire_String(apiObj.credential);
  }

  void _api_fill_to_wire_video_constraints(
      VideoConstraints apiObj, wire_VideoConstraints wireObj) {
    wireObj.device_id = api2wire_opt_String(apiObj.deviceId);
    wireObj.width = api2wire_u32(apiObj.width);
    wireObj.height = api2wire_u32(apiObj.height);
    wireObj.frame_rate = api2wire_u32(apiObj.frameRate);
    wireObj.is_display = api2wire_bool(apiObj.isDisplay);
  }
}

// ignore_for_file: camel_case_types, non_constant_identifier_names, avoid_positional_boolean_parameters, annotate_overrides, constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.

/// generated by flutter_rust_bridge
class FlutterWebrtcNativeWire implements FlutterRustBridgeWireBase {
  @internal
  late final dartApi = DartApiDl(init_frb_dart_api_dl);

  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  FlutterWebrtcNativeWire(ffi.DynamicLibrary dynamicLibrary)
      : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  FlutterWebrtcNativeWire.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  void store_dart_post_cobject(
    DartPostCObjectFnType ptr,
  ) {
    return _store_dart_post_cobject(
      ptr,
    );
  }

  late final _store_dart_post_cobjectPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(DartPostCObjectFnType)>>(
          'store_dart_post_cobject');
  late final _store_dart_post_cobject = _store_dart_post_cobjectPtr
      .asFunction<void Function(DartPostCObjectFnType)>();

  Object get_dart_object(
    int ptr,
  ) {
    return _get_dart_object(
      ptr,
    );
  }

  late final _get_dart_objectPtr =
      _lookup<ffi.NativeFunction<ffi.Handle Function(ffi.UintPtr)>>(
          'get_dart_object');
  late final _get_dart_object =
      _get_dart_objectPtr.asFunction<Object Function(int)>();

  void drop_dart_object(
    int ptr,
  ) {
    return _drop_dart_object(
      ptr,
    );
  }

  late final _drop_dart_objectPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.UintPtr)>>(
          'drop_dart_object');
  late final _drop_dart_object =
      _drop_dart_objectPtr.asFunction<void Function(int)>();

  int new_dart_opaque(
    Object handle,
  ) {
    return _new_dart_opaque(
      handle,
    );
  }

  late final _new_dart_opaquePtr =
      _lookup<ffi.NativeFunction<ffi.UintPtr Function(ffi.Handle)>>(
          'new_dart_opaque');
  late final _new_dart_opaque =
      _new_dart_opaquePtr.asFunction<int Function(Object)>();

  int init_frb_dart_api_dl(
    ffi.Pointer<ffi.Void> obj,
  ) {
    return _init_frb_dart_api_dl(
      obj,
    );
  }

  late final _init_frb_dart_api_dlPtr =
      _lookup<ffi.NativeFunction<ffi.IntPtr Function(ffi.Pointer<ffi.Void>)>>(
          'init_frb_dart_api_dl');
  late final _init_frb_dart_api_dl = _init_frb_dart_api_dlPtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>)>();

  void wire_enable_fake_media(
    int port_,
  ) {
    return _wire_enable_fake_media(
      port_,
    );
  }

  late final _wire_enable_fake_mediaPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_enable_fake_media');
  late final _wire_enable_fake_media =
      _wire_enable_fake_mediaPtr.asFunction<void Function(int)>();

  void wire_is_fake_media(
    int port_,
  ) {
    return _wire_is_fake_media(
      port_,
    );
  }

  late final _wire_is_fake_mediaPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_is_fake_media');
  late final _wire_is_fake_media =
      _wire_is_fake_mediaPtr.asFunction<void Function(int)>();

  void wire_enumerate_devices(
    int port_,
  ) {
    return _wire_enumerate_devices(
      port_,
    );
  }

  late final _wire_enumerate_devicesPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_enumerate_devices');
  late final _wire_enumerate_devices =
      _wire_enumerate_devicesPtr.asFunction<void Function(int)>();

  void wire_enumerate_system_audio_source(
    int port_,
  ) {
    return _wire_enumerate_system_audio_source(
      port_,
    );
  }

  late final _wire_enumerate_system_audio_sourcePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_enumerate_system_audio_source');
  late final _wire_enumerate_system_audio_source =
      _wire_enumerate_system_audio_sourcePtr.asFunction<void Function(int)>();

  void wire_enumerate_displays(
    int port_,
  ) {
    return _wire_enumerate_displays(
      port_,
    );
  }

  late final _wire_enumerate_displaysPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_enumerate_displays');
  late final _wire_enumerate_displays =
      _wire_enumerate_displaysPtr.asFunction<void Function(int)>();

  void wire_create_peer_connection(
    int port_,
    ffi.Pointer<wire_RtcConfiguration> configuration,
  ) {
    return _wire_create_peer_connection(
      port_,
      configuration,
    );
  }

  late final _wire_create_peer_connectionPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Int64, ffi.Pointer<wire_RtcConfiguration>)>>(
      'wire_create_peer_connection');
  late final _wire_create_peer_connection = _wire_create_peer_connectionPtr
      .asFunction<void Function(int, ffi.Pointer<wire_RtcConfiguration>)>();

  void wire_create_offer(
    int port_,
    int peer_id,
    bool voice_activity_detection,
    bool ice_restart,
    bool use_rtp_mux,
  ) {
    return _wire_create_offer(
      port_,
      peer_id,
      voice_activity_detection,
      ice_restart,
      use_rtp_mux,
    );
  }

  late final _wire_create_offerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Bool, ffi.Bool,
              ffi.Bool)>>('wire_create_offer');
  late final _wire_create_offer = _wire_create_offerPtr
      .asFunction<void Function(int, int, bool, bool, bool)>();

  void wire_create_answer(
    int port_,
    int peer_id,
    bool voice_activity_detection,
    bool ice_restart,
    bool use_rtp_mux,
  ) {
    return _wire_create_answer(
      port_,
      peer_id,
      voice_activity_detection,
      ice_restart,
      use_rtp_mux,
    );
  }

  late final _wire_create_answerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Bool, ffi.Bool,
              ffi.Bool)>>('wire_create_answer');
  late final _wire_create_answer = _wire_create_answerPtr
      .asFunction<void Function(int, int, bool, bool, bool)>();

  void wire_set_local_description(
    int port_,
    int peer_id,
    int kind,
    ffi.Pointer<wire_uint_8_list> sdp,
  ) {
    return _wire_set_local_description(
      port_,
      peer_id,
      kind,
      sdp,
    );
  }

  late final _wire_set_local_descriptionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Int32,
              ffi.Pointer<wire_uint_8_list>)>>('wire_set_local_description');
  late final _wire_set_local_description =
      _wire_set_local_descriptionPtr.asFunction<
          void Function(int, int, int, ffi.Pointer<wire_uint_8_list>)>();

  void wire_set_remote_description(
    int port_,
    int peer_id,
    int kind,
    ffi.Pointer<wire_uint_8_list> sdp,
  ) {
    return _wire_set_remote_description(
      port_,
      peer_id,
      kind,
      sdp,
    );
  }

  late final _wire_set_remote_descriptionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Int32,
              ffi.Pointer<wire_uint_8_list>)>>('wire_set_remote_description');
  late final _wire_set_remote_description =
      _wire_set_remote_descriptionPtr.asFunction<
          void Function(int, int, int, ffi.Pointer<wire_uint_8_list>)>();

  void wire_add_transceiver(
    int port_,
    int peer_id,
    int media_type,
    int direction,
  ) {
    return _wire_add_transceiver(
      port_,
      peer_id,
      media_type,
      direction,
    );
  }

  late final _wire_add_transceiverPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Int32,
              ffi.Int32)>>('wire_add_transceiver');
  late final _wire_add_transceiver =
      _wire_add_transceiverPtr.asFunction<void Function(int, int, int, int)>();

  void wire_get_transceivers(
    int port_,
    int peer_id,
  ) {
    return _wire_get_transceivers(
      port_,
      peer_id,
    );
  }

  late final _wire_get_transceiversPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Uint64)>>(
          'wire_get_transceivers');
  late final _wire_get_transceivers =
      _wire_get_transceiversPtr.asFunction<void Function(int, int)>();

  void wire_set_transceiver_direction(
    int port_,
    int peer_id,
    int transceiver_index,
    int direction,
  ) {
    return _wire_set_transceiver_direction(
      port_,
      peer_id,
      transceiver_index,
      direction,
    );
  }

  late final _wire_set_transceiver_directionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Uint32,
              ffi.Int32)>>('wire_set_transceiver_direction');
  late final _wire_set_transceiver_direction =
      _wire_set_transceiver_directionPtr
          .asFunction<void Function(int, int, int, int)>();

  void wire_set_transceiver_recv(
    int port_,
    int peer_id,
    int transceiver_index,
    bool recv,
  ) {
    return _wire_set_transceiver_recv(
      port_,
      peer_id,
      transceiver_index,
      recv,
    );
  }

  late final _wire_set_transceiver_recvPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Uint32,
              ffi.Bool)>>('wire_set_transceiver_recv');
  late final _wire_set_transceiver_recv = _wire_set_transceiver_recvPtr
      .asFunction<void Function(int, int, int, bool)>();

  void wire_set_transceiver_send(
    int port_,
    int peer_id,
    int transceiver_index,
    bool send,
  ) {
    return _wire_set_transceiver_send(
      port_,
      peer_id,
      transceiver_index,
      send,
    );
  }

  late final _wire_set_transceiver_sendPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Uint32,
              ffi.Bool)>>('wire_set_transceiver_send');
  late final _wire_set_transceiver_send = _wire_set_transceiver_sendPtr
      .asFunction<void Function(int, int, int, bool)>();

  void wire_get_transceiver_mid(
    int port_,
    int peer_id,
    int transceiver_index,
  ) {
    return _wire_get_transceiver_mid(
      port_,
      peer_id,
      transceiver_index,
    );
  }

  late final _wire_get_transceiver_midPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Int64, ffi.Uint64, ffi.Uint32)>>('wire_get_transceiver_mid');
  late final _wire_get_transceiver_mid =
      _wire_get_transceiver_midPtr.asFunction<void Function(int, int, int)>();

  void wire_get_transceiver_direction(
    int port_,
    int peer_id,
    int transceiver_index,
  ) {
    return _wire_get_transceiver_direction(
      port_,
      peer_id,
      transceiver_index,
    );
  }

  late final _wire_get_transceiver_directionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64,
              ffi.Uint32)>>('wire_get_transceiver_direction');
  late final _wire_get_transceiver_direction =
      _wire_get_transceiver_directionPtr
          .asFunction<void Function(int, int, int)>();

  void wire_get_peer_stats(
    int port_,
    int peer_id,
  ) {
    return _wire_get_peer_stats(
      port_,
      peer_id,
    );
  }

  late final _wire_get_peer_statsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Uint64)>>(
          'wire_get_peer_stats');
  late final _wire_get_peer_stats =
      _wire_get_peer_statsPtr.asFunction<void Function(int, int)>();

  void wire_stop_transceiver(
    int port_,
    int peer_id,
    int transceiver_index,
  ) {
    return _wire_stop_transceiver(
      port_,
      peer_id,
      transceiver_index,
    );
  }

  late final _wire_stop_transceiverPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Int64, ffi.Uint64, ffi.Uint32)>>('wire_stop_transceiver');
  late final _wire_stop_transceiver =
      _wire_stop_transceiverPtr.asFunction<void Function(int, int, int)>();

  void wire_sender_replace_track(
    int port_,
    int peer_id,
    int transceiver_index,
    ffi.Pointer<wire_uint_8_list> track_id,
  ) {
    return _wire_sender_replace_track(
      port_,
      peer_id,
      transceiver_index,
      track_id,
    );
  }

  late final _wire_sender_replace_trackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Uint64, ffi.Uint32,
              ffi.Pointer<wire_uint_8_list>)>>('wire_sender_replace_track');
  late final _wire_sender_replace_track =
      _wire_sender_replace_trackPtr.asFunction<
          void Function(int, int, int, ffi.Pointer<wire_uint_8_list>)>();

  void wire_add_ice_candidate(
    int port_,
    int peer_id,
    ffi.Pointer<wire_uint_8_list> candidate,
    ffi.Pointer<wire_uint_8_list> sdp_mid,
    int sdp_mline_index,
  ) {
    return _wire_add_ice_candidate(
      port_,
      peer_id,
      candidate,
      sdp_mid,
      sdp_mline_index,
    );
  }

  late final _wire_add_ice_candidatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Int64,
              ffi.Uint64,
              ffi.Pointer<wire_uint_8_list>,
              ffi.Pointer<wire_uint_8_list>,
              ffi.Int32)>>('wire_add_ice_candidate');
  late final _wire_add_ice_candidate = _wire_add_ice_candidatePtr.asFunction<
      void Function(int, int, ffi.Pointer<wire_uint_8_list>,
          ffi.Pointer<wire_uint_8_list>, int)>();

  void wire_restart_ice(
    int port_,
    int peer_id,
  ) {
    return _wire_restart_ice(
      port_,
      peer_id,
    );
  }

  late final _wire_restart_icePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Uint64)>>(
          'wire_restart_ice');
  late final _wire_restart_ice =
      _wire_restart_icePtr.asFunction<void Function(int, int)>();

  void wire_dispose_peer_connection(
    int port_,
    int peer_id,
  ) {
    return _wire_dispose_peer_connection(
      port_,
      peer_id,
    );
  }

  late final _wire_dispose_peer_connectionPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Uint64)>>(
          'wire_dispose_peer_connection');
  late final _wire_dispose_peer_connection =
      _wire_dispose_peer_connectionPtr.asFunction<void Function(int, int)>();

  void wire_get_media(
    int port_,
    ffi.Pointer<wire_MediaStreamConstraints> constraints,
  ) {
    return _wire_get_media(
      port_,
      constraints,
    );
  }

  late final _wire_get_mediaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64,
              ffi.Pointer<wire_MediaStreamConstraints>)>>('wire_get_media');
  late final _wire_get_media = _wire_get_mediaPtr.asFunction<
      void Function(int, ffi.Pointer<wire_MediaStreamConstraints>)>();

  void wire_set_audio_playout_device(
    int port_,
    ffi.Pointer<wire_uint_8_list> device_id,
  ) {
    return _wire_set_audio_playout_device(
      port_,
      device_id,
    );
  }

  late final _wire_set_audio_playout_devicePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64,
              ffi.Pointer<wire_uint_8_list>)>>('wire_set_audio_playout_device');
  late final _wire_set_audio_playout_device = _wire_set_audio_playout_devicePtr
      .asFunction<void Function(int, ffi.Pointer<wire_uint_8_list>)>();

  void wire_microphone_volume_is_available(
    int port_,
  ) {
    return _wire_microphone_volume_is_available(
      port_,
    );
  }

  late final _wire_microphone_volume_is_availablePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_microphone_volume_is_available');
  late final _wire_microphone_volume_is_available =
      _wire_microphone_volume_is_availablePtr.asFunction<void Function(int)>();

  void wire_set_microphone_volume(
    int port_,
    int level,
  ) {
    return _wire_set_microphone_volume(
      port_,
      level,
    );
  }

  late final _wire_set_microphone_volumePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Uint8)>>(
          'wire_set_microphone_volume');
  late final _wire_set_microphone_volume =
      _wire_set_microphone_volumePtr.asFunction<void Function(int, int)>();

  void wire_microphone_volume(
    int port_,
  ) {
    return _wire_microphone_volume(
      port_,
    );
  }

  late final _wire_microphone_volumePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_microphone_volume');
  late final _wire_microphone_volume =
      _wire_microphone_volumePtr.asFunction<void Function(int)>();

  void wire_dispose_track(
    int port_,
    ffi.Pointer<wire_uint_8_list> track_id,
    int kind,
  ) {
    return _wire_dispose_track(
      port_,
      track_id,
      kind,
    );
  }

  late final _wire_dispose_trackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Pointer<wire_uint_8_list>,
              ffi.Int32)>>('wire_dispose_track');
  late final _wire_dispose_track = _wire_dispose_trackPtr
      .asFunction<void Function(int, ffi.Pointer<wire_uint_8_list>, int)>();

  void wire_track_state(
    int port_,
    ffi.Pointer<wire_uint_8_list> track_id,
    int kind,
  ) {
    return _wire_track_state(
      port_,
      track_id,
      kind,
    );
  }

  late final _wire_track_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Pointer<wire_uint_8_list>,
              ffi.Int32)>>('wire_track_state');
  late final _wire_track_state = _wire_track_statePtr
      .asFunction<void Function(int, ffi.Pointer<wire_uint_8_list>, int)>();

  void wire_set_track_enabled(
    int port_,
    ffi.Pointer<wire_uint_8_list> track_id,
    int kind,
    bool enabled,
  ) {
    return _wire_set_track_enabled(
      port_,
      track_id,
      kind,
      enabled,
    );
  }

  late final _wire_set_track_enabledPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Pointer<wire_uint_8_list>, ffi.Int32,
              ffi.Bool)>>('wire_set_track_enabled');
  late final _wire_set_track_enabled = _wire_set_track_enabledPtr.asFunction<
      void Function(int, ffi.Pointer<wire_uint_8_list>, int, bool)>();

  void wire_clone_track(
    int port_,
    ffi.Pointer<wire_uint_8_list> track_id,
    int kind,
  ) {
    return _wire_clone_track(
      port_,
      track_id,
      kind,
    );
  }

  late final _wire_clone_trackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Pointer<wire_uint_8_list>,
              ffi.Int32)>>('wire_clone_track');
  late final _wire_clone_track = _wire_clone_trackPtr
      .asFunction<void Function(int, ffi.Pointer<wire_uint_8_list>, int)>();

  void wire_set_system_audio_volume(
    int port_,
    double level,
  ) {
    return _wire_set_system_audio_volume(
      port_,
      level,
    );
  }

  late final _wire_set_system_audio_volumePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Float)>>(
          'wire_set_system_audio_volume');
  late final _wire_set_system_audio_volume =
      _wire_set_system_audio_volumePtr.asFunction<void Function(int, double)>();

  void wire_system_audio_volume(
    int port_,
  ) {
    return _wire_system_audio_volume(
      port_,
    );
  }

  late final _wire_system_audio_volumePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_system_audio_volume');
  late final _wire_system_audio_volume =
      _wire_system_audio_volumePtr.asFunction<void Function(int)>();

  void wire_register_track_observer(
    int port_,
    ffi.Pointer<wire_uint_8_list> track_id,
    int kind,
  ) {
    return _wire_register_track_observer(
      port_,
      track_id,
      kind,
    );
  }

  late final _wire_register_track_observerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Pointer<wire_uint_8_list>,
              ffi.Int32)>>('wire_register_track_observer');
  late final _wire_register_track_observer = _wire_register_track_observerPtr
      .asFunction<void Function(int, ffi.Pointer<wire_uint_8_list>, int)>();

  void wire_set_on_device_changed(
    int port_,
  ) {
    return _wire_set_on_device_changed(
      port_,
    );
  }

  late final _wire_set_on_device_changedPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64)>>(
          'wire_set_on_device_changed');
  late final _wire_set_on_device_changed =
      _wire_set_on_device_changedPtr.asFunction<void Function(int)>();

  void wire_set_on_audio_level_changed(
    int port_,
    ffi.Pointer<wire_uint_8_list> track_id,
  ) {
    return _wire_set_on_audio_level_changed(
      port_,
      track_id,
    );
  }

  late final _wire_set_on_audio_level_changedPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Int64, ffi.Pointer<wire_uint_8_list>)>>(
      'wire_set_on_audio_level_changed');
  late final _wire_set_on_audio_level_changed =
      _wire_set_on_audio_level_changedPtr
          .asFunction<void Function(int, ffi.Pointer<wire_uint_8_list>)>();

  void wire_create_video_sink(
    int port_,
    int sink_id,
    ffi.Pointer<wire_uint_8_list> track_id,
    int callback_ptr,
  ) {
    return _wire_create_video_sink(
      port_,
      sink_id,
      track_id,
      callback_ptr,
    );
  }

  late final _wire_create_video_sinkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int64, ffi.Int64, ffi.Pointer<wire_uint_8_list>,
              ffi.Uint64)>>('wire_create_video_sink');
  late final _wire_create_video_sink = _wire_create_video_sinkPtr.asFunction<
      void Function(int, int, ffi.Pointer<wire_uint_8_list>, int)>();

  void wire_dispose_video_sink(
    int port_,
    int sink_id,
  ) {
    return _wire_dispose_video_sink(
      port_,
      sink_id,
    );
  }

  late final _wire_dispose_video_sinkPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int64, ffi.Int64)>>(
          'wire_dispose_video_sink');
  late final _wire_dispose_video_sink =
      _wire_dispose_video_sinkPtr.asFunction<void Function(int, int)>();

  ffi.Pointer<wire_StringList> new_StringList_0(
    int len,
  ) {
    return _new_StringList_0(
      len,
    );
  }

  late final _new_StringList_0Ptr = _lookup<
          ffi.NativeFunction<ffi.Pointer<wire_StringList> Function(ffi.Int32)>>(
      'new_StringList_0');
  late final _new_StringList_0 = _new_StringList_0Ptr
      .asFunction<ffi.Pointer<wire_StringList> Function(int)>();

  ffi.Pointer<wire_AudioConstraints> new_box_autoadd_audio_constraints_0() {
    return _new_box_autoadd_audio_constraints_0();
  }

  late final _new_box_autoadd_audio_constraints_0Ptr = _lookup<
          ffi.NativeFunction<ffi.Pointer<wire_AudioConstraints> Function()>>(
      'new_box_autoadd_audio_constraints_0');
  late final _new_box_autoadd_audio_constraints_0 =
      _new_box_autoadd_audio_constraints_0Ptr
          .asFunction<ffi.Pointer<wire_AudioConstraints> Function()>();

  ffi.Pointer<ffi.Int64> new_box_autoadd_i64_0(
    int value,
  ) {
    return _new_box_autoadd_i64_0(
      value,
    );
  }

  late final _new_box_autoadd_i64_0Ptr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int64> Function(ffi.Int64)>>(
          'new_box_autoadd_i64_0');
  late final _new_box_autoadd_i64_0 = _new_box_autoadd_i64_0Ptr
      .asFunction<ffi.Pointer<ffi.Int64> Function(int)>();

  ffi.Pointer<wire_MediaStreamConstraints>
      new_box_autoadd_media_stream_constraints_0() {
    return _new_box_autoadd_media_stream_constraints_0();
  }

  late final _new_box_autoadd_media_stream_constraints_0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<wire_MediaStreamConstraints>
              Function()>>('new_box_autoadd_media_stream_constraints_0');
  late final _new_box_autoadd_media_stream_constraints_0 =
      _new_box_autoadd_media_stream_constraints_0Ptr
          .asFunction<ffi.Pointer<wire_MediaStreamConstraints> Function()>();

  ffi.Pointer<wire_RtcConfiguration> new_box_autoadd_rtc_configuration_0() {
    return _new_box_autoadd_rtc_configuration_0();
  }

  late final _new_box_autoadd_rtc_configuration_0Ptr = _lookup<
          ffi.NativeFunction<ffi.Pointer<wire_RtcConfiguration> Function()>>(
      'new_box_autoadd_rtc_configuration_0');
  late final _new_box_autoadd_rtc_configuration_0 =
      _new_box_autoadd_rtc_configuration_0Ptr
          .asFunction<ffi.Pointer<wire_RtcConfiguration> Function()>();

  ffi.Pointer<wire_VideoConstraints> new_box_autoadd_video_constraints_0() {
    return _new_box_autoadd_video_constraints_0();
  }

  late final _new_box_autoadd_video_constraints_0Ptr = _lookup<
          ffi.NativeFunction<ffi.Pointer<wire_VideoConstraints> Function()>>(
      'new_box_autoadd_video_constraints_0');
  late final _new_box_autoadd_video_constraints_0 =
      _new_box_autoadd_video_constraints_0Ptr
          .asFunction<ffi.Pointer<wire_VideoConstraints> Function()>();

  ffi.Pointer<wire_list_rtc_ice_server> new_list_rtc_ice_server_0(
    int len,
  ) {
    return _new_list_rtc_ice_server_0(
      len,
    );
  }

  late final _new_list_rtc_ice_server_0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<wire_list_rtc_ice_server> Function(
              ffi.Int32)>>('new_list_rtc_ice_server_0');
  late final _new_list_rtc_ice_server_0 = _new_list_rtc_ice_server_0Ptr
      .asFunction<ffi.Pointer<wire_list_rtc_ice_server> Function(int)>();

  ffi.Pointer<wire_uint_8_list> new_uint_8_list_0(
    int len,
  ) {
    return _new_uint_8_list_0(
      len,
    );
  }

  late final _new_uint_8_list_0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<wire_uint_8_list> Function(
              ffi.Int32)>>('new_uint_8_list_0');
  late final _new_uint_8_list_0 = _new_uint_8_list_0Ptr
      .asFunction<ffi.Pointer<wire_uint_8_list> Function(int)>();

  void free_WireSyncReturn(
    WireSyncReturn ptr,
  ) {
    return _free_WireSyncReturn(
      ptr,
    );
  }

  late final _free_WireSyncReturnPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(WireSyncReturn)>>(
          'free_WireSyncReturn');
  late final _free_WireSyncReturn =
      _free_WireSyncReturnPtr.asFunction<void Function(WireSyncReturn)>();
}

class _Dart_Handle extends ffi.Opaque {}

class wire_uint_8_list extends ffi.Struct {
  external ffi.Pointer<ffi.Uint8> ptr;

  @ffi.Int32()
  external int len;
}

class wire_StringList extends ffi.Struct {
  external ffi.Pointer<ffi.Pointer<wire_uint_8_list>> ptr;

  @ffi.Int32()
  external int len;
}

class wire_RtcIceServer extends ffi.Struct {
  external ffi.Pointer<wire_StringList> urls;

  external ffi.Pointer<wire_uint_8_list> username;

  external ffi.Pointer<wire_uint_8_list> credential;
}

class wire_list_rtc_ice_server extends ffi.Struct {
  external ffi.Pointer<wire_RtcIceServer> ptr;

  @ffi.Int32()
  external int len;
}

class wire_RtcConfiguration extends ffi.Struct {
  @ffi.Int32()
  external int ice_transport_policy;

  @ffi.Int32()
  external int bundle_policy;

  external ffi.Pointer<wire_list_rtc_ice_server> ice_servers;
}

class wire_AudioConstraints extends ffi.Struct {
  external ffi.Pointer<wire_uint_8_list> device_id;

  external ffi.Pointer<ffi.Int64> system_id;
}

class wire_VideoConstraints extends ffi.Struct {
  external ffi.Pointer<wire_uint_8_list> device_id;

  @ffi.Uint32()
  external int width;

  @ffi.Uint32()
  external int height;

  @ffi.Uint32()
  external int frame_rate;

  @ffi.Bool()
  external bool is_display;
}

class wire_MediaStreamConstraints extends ffi.Struct {
  external ffi.Pointer<wire_AudioConstraints> audio;

  external ffi.Pointer<wire_VideoConstraints> video;
}

typedef DartPostCObjectFnType = ffi.Pointer<
    ffi.NativeFunction<ffi.Bool Function(DartPort, ffi.Pointer<ffi.Void>)>>;
typedef DartPort = ffi.Int64;
